{
  "total_workflows": 65,
  "trigger_summary": {
    "workflow_run": [
      "Self-Test SR-AIbridge"
    ],
    "workflow_dispatch": [
      "Self-Test SR-AIbridge"
    ],
    "schedule": [
      "Self-Test SR-AIbridge"
    ]
  },
  "duplicate_triggers": {},
  "optimization_opportunities": [
    {
      "workflow": "Deploy Preview (Bridge Preflight)",
      "job": "preflight",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Deploy Preview (Bridge Preflight)",
      "job": "preflight",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Deploy Preview (Bridge Preflight)",
      "job": "preflight",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Deploy Preview (Bridge Preflight)",
      "job": "netlify-preview",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "BRH Build & Publish",
      "job": "build",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "analyze-and-route",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "test-backend",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "build-frontend",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "deploy-preview",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "deploy-production",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "report-costs",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Example - Sovereign CI/CD",
      "job": "report-costs",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Sync Feedback",
      "job": "bridge-feedback",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Netlify Validation (Umbra v1.9.7e)",
      "job": "validate-netlify",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Netlify Validation (Umbra v1.9.7e)",
      "job": "validate-netlify",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Build Triage (Netlify)",
      "job": "build-triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Build Triage (Netlify)",
      "job": "build-triage",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Browser Dependency Resolution (Firewall Bypass)",
      "job": "resolve-browser-deps",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Budget Monitor",
      "job": "monitor-budget",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Budget Monitor",
      "job": "monitor-budget",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Budget Monitor",
      "job": "notify",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Deploy Path Verification",
      "job": "verify-deploy-paths",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Bridge Deploy Path Verification",
      "job": "verify-deploy-paths",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Bridge Deploy Path Verification",
      "job": "verify-deploy-paths",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Healer-Net Global Diagnostics",
      "job": "healernet",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Healer-Net Global Diagnostics",
      "job": "healernet",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Healer-Net Global Diagnostics",
      "job": "healernet",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Triage Pre-Seed",
      "job": "preseed",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Triage Pre-Seed",
      "job": "preseed",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Auto-Deploy Mode (DISABLED - Use deploy.yml)",
      "job": "bridge-autodeploy",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Build & Deploy SR-AIbridge",
      "job": "predictive-deploy",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Build & Deploy SR-AIbridge",
      "job": "predictive-deploy",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Build & Deploy SR-AIbridge",
      "job": "predictive-deploy",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Build & Deploy SR-AIbridge",
      "job": "deploy-frontend",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Build & Deploy SR-AIbridge",
      "job": "deploy-backend",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Build & Deploy SR-AIbridge",
      "job": "verify-build",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Repo Codex Compiler",
      "job": "build",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Repo Codex Compiler",
      "job": "build",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Repo Codex Compiler",
      "job": "build",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83d\udd01 Build & Deploy Triage (DISABLED - Use deploy.yml)",
      "job": "triage",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83d\udd01 Build & Deploy Triage (DISABLED - Use deploy.yml)",
      "job": "triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "\ud83d\udd01 Build & Deploy Triage (DISABLED - Use deploy.yml)",
      "job": "triage",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83e\uddf9 Bridge Diagnostic Retention",
      "job": "retention",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83e\uddf9 Bridge Diagnostic Retention",
      "job": "retention",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Environment Auto-Repair & Verification",
      "job": "autoheal",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Environment Auto-Repair & Verification",
      "job": "autoheal",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Endpoint DeepScan Triage",
      "job": "deep-scan",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Endpoint DeepScan Triage",
      "job": "deep-scan",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Firewall Harmony",
      "job": "harmony",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Harmony",
      "job": "harmony",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Firewall Intelligence - Nightly Scan",
      "job": "firewall-intelligence",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Firewall Intelligence - Nightly Scan",
      "job": "firewall-intelligence",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Intelligence - Nightly Scan",
      "job": "firewall-intelligence",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Intelligence - Nightly Scan",
      "job": "firewall-intelligence",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83d\udd01 Bridge Env Sync",
      "job": "sync",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83d\udd01 Bridge Env Sync",
      "job": "sync",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "\ud83d\udd01 Bridge Env Sync",
      "job": "sync",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "\ud83d\udd01 Bridge Env Sync",
      "job": "sync",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Quantum Dominion Security",
      "job": "quantum-security",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Hooks Triage",
      "job": "hooks-triage",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Hooks Triage",
      "job": "hooks-triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Hooks Triage",
      "job": "hooks-triage",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Environment Parity Guard",
      "job": "env-parity",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Environment Parity Guard",
      "job": "env-parity",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Triage Federation Heartbeat",
      "job": "triage",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Triage Federation Heartbeat",
      "job": "triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "EAN Reflex Loop",
      "job": "reflex",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Firewall Intelligence and Autonomy Engine",
      "job": "firewall-autonomy",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Firewall Intelligence and Autonomy Engine",
      "job": "firewall-autonomy",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Intelligence and Autonomy Engine",
      "job": "firewall-autonomy",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Intelligence and Autonomy Engine",
      "job": "firewall-autonomy",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Intelligence and Autonomy Engine",
      "job": "firewall-autonomy",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Self-Test SR-AIbridge",
      "job": "wait-for-deployment",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Self-Test SR-AIbridge",
      "job": "backend-health-tests",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Self-Test SR-AIbridge",
      "job": "backend-health-tests",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Self-Test SR-AIbridge",
      "job": "frontend-connectivity-test",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Self-Test SR-AIbridge",
      "job": "notify-results",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Autonomy Healer",
      "job": "heal",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Build Preflight (Triage)",
      "job": "triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Build Preflight (Triage)",
      "job": "triage",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83c\udf09 Bridge Deploy (DISABLED - Use deploy.yml)",
      "job": "build-and-deploy",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83c\udf09 Bridge Deploy (DISABLED - Use deploy.yml)",
      "job": "build-and-deploy",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "EnvSync Manifest Validation",
      "job": "validate-manifest",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Sovereign Diagnostic Sweep",
      "job": "failure-hunter",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Sovereign Diagnostic Sweep",
      "job": "failure-hunter",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Sovereign Diagnostic Sweep",
      "job": "failure-hunter",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Embedded Autonomy Node",
      "job": "autonomy-node",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Integrity CI",
      "job": "validate",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Integrity CI",
      "job": "emit-incidents-on-fail",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Compliance Scan (Licenses & Counterfeit)",
      "job": "scan",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Compliance Scan (Licenses & Counterfeit)",
      "job": "scan",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Compliance Scan (Licenses & Counterfeit)",
      "job": "scan",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83c\udf0c Git Sovereign Operations",
      "job": "git_sovereign_commissioning",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83c\udf0c Git Sovereign Operations",
      "job": "git_sovereign_commissioning",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83c\udf0c Git Sovereign Operations",
      "job": "autonomous_operations",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83c\udf0c Git Sovereign Operations",
      "job": "autonomous_operations",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "\ud83c\udf0c Git Sovereign Operations",
      "job": "sovereignty_report",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "\ud83c\udf0c Git Sovereign Operations",
      "job": "sovereignty_report",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Consolidated CI - Optimized",
      "job": "ci-complete",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "API Triage",
      "job": "api-triage",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "API Triage",
      "job": "api-triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "API Triage",
      "job": "api-triage",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Endpoint Triage",
      "job": "triage",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Endpoint Triage",
      "job": "triage",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Endpoint Triage",
      "job": "triage",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Diagnostics Federation (DISABLED - Use deploy.yml)",
      "job": "federate",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Environment Sync",
      "job": "sync",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Environment Sync",
      "job": "sync",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Copilot Network Diagnostics",
      "job": "verify_network",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Copilot Network Diagnostics",
      "job": "verify_network",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Copilot Network Diagnostics",
      "job": "verify_network",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Firewall Gate - Deploy Failure Analysis",
      "job": "firewall-gate",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Firewall Gate - Deploy Failure Analysis",
      "job": "firewall-gate",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Firewall Gate - Deploy Failure Analysis",
      "job": "firewall-gate",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Unified Health Timeline",
      "job": "sync",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Unified Health Timeline",
      "job": "sync",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Unified Health Timeline",
      "job": "sync",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Reflex Auto-Merge",
      "job": "reflex",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Reflex Auto-Merge",
      "job": "reflex",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Parity Auto-Fix",
      "job": "parity_autofix",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Bridge Parity Auto-Fix",
      "job": "parity_autofix",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Environment Stabilization & Confidence Check",
      "job": "stabilize",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Environment Stabilization & Confidence Check",
      "job": "stabilize",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Environment Stabilization & Confidence Check",
      "job": "stabilize",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Copilot PreFlight Environment Setup",
      "job": "preflight",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Copilot PreFlight Environment Setup",
      "job": "preflight",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Native Runner Configuration",
      "job": "runner-info",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Deploy Gate",
      "job": "gate",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Federation Deep-Seek",
      "job": "deepseek",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Federation Deep-Seek",
      "job": "deepseek",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Federation Deep-Seek",
      "job": "deepseek",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Endpoints & Hooks Sweep",
      "job": "sweep",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Endpoints & Hooks Sweep",
      "job": "sweep",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Endpoints & Hooks Sweep",
      "job": "sweep",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Parity & Triage Engine",
      "job": "parity",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Bridge Parity & Triage Engine",
      "job": "parity",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Autonomy Diagnostic Pulse (Autonomous Mode)",
      "job": "run-bridge-selftest",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Autonomy Diagnostic Pulse (Autonomous Mode)",
      "job": "run-bridge-selftest",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Bridge Autonomy Diagnostic Pulse (Autonomous Mode)",
      "job": "run-bridge-selftest",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "predict",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "predict",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "repair",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "repair",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "certify",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "certify",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "guardian",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Total Autonomy Protocol",
      "job": "guardian",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Netlify Config Guard",
      "job": "guard",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Netlify Config Guard",
      "job": "guard",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "job": "build",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "job": "build",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "job": "triage_heartbeat",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "job": "quantum_dominion",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "job": "deploy",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "job": "finalize",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Run ARIE Integrity Check Now",
      "job": "arie_run",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Run ARIE Integrity Check Now",
      "job": "arie_run",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Compliance Enforcement",
      "job": "verify",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Compliance Enforcement",
      "job": "verify",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 30 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Bridge Compliance Enforcement",
      "job": "verify",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "forge-authenticate",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "forge-authenticate",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "validate-manifest",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "validate-manifest",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "deploy-runtime",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "deploy-runtime",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Bridge Deploy (Sovereign Deploy Protocol)",
      "job": "post-deploy-health",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "EnvSync After Merge",
      "job": "envsync",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Federation Runtime Guard v2",
      "job": "guard",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Federation Runtime Guard v2",
      "job": "guard",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Netlify Config Guard & Egress Sync (v1.8.3)",
      "job": "guard",
      "type": "high_artifact_retention",
      "severity": "medium",
      "description": "Artifact retention set to 90 days (recommend 7)",
      "savings_estimate": "Storage cost reduction"
    },
    {
      "workflow": "Netlify Config Guard & Egress Sync (v1.8.3)",
      "job": "guard",
      "type": "missing_timeout",
      "severity": "medium",
      "description": "No timeout set (default 360 minutes)",
      "savings_estimate": "Prevent runaway jobs"
    },
    {
      "workflow": "Deploy Preview (Bridge Preflight)",
      "job": "preflight",
      "type": "missing_cache",
      "severity": "high",
      "description": "Dependencies installed without caching",
      "savings_estimate": "30-60 seconds per run"
    }
  ],
  "workflows": [
    {
      "file": "deploy_preview.yml",
      "name": "Deploy Preview (Bridge Preflight)",
      "config": {
        "name": "Deploy Preview (Bridge Preflight)",
        "true": {
          "pull_request": {
            "types": [
              "opened",
              "synchronize",
              "reopened",
              "ready_for_review"
            ]
          }
        },
        "permissions": {
          "contents": "write",
          "actions": "read"
        },
        "jobs": {
          "preflight": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout (PR)",
                "uses": "actions/checkout@v4",
                "with": {
                  "fetch-depth": 0
                }
              },
              {
                "name": "Setup Node",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install backend deps",
                "run": "python -m pip install -U pip\npip install -r requirements.txt\n"
              },
              {
                "name": "Preflight (Chimera)",
                "run": "python - <<'PY'\nfrom pathlib import Path\nfrom bridge_backend.engines.chimera.core import ChimeraEngine\nimport asyncio\nasync def main():\n    eng = ChimeraEngine(Path(\".\").resolve())\n    await eng.preflight()\nasyncio.run(main())\nPY\n"
              },
              {
                "name": "Commit generated deploy artifacts if changed",
                "run": "set -e\ngit config user.name \"bridge-bot\"\ngit config user.email \"bridge-bot@users.noreply.github.com\"\ngit add _headers _redirects netlify.toml || true\nif ! git diff --cached --quiet; then\n  git commit -m \"chore(preflight): update deploy artifacts\"\n  git push\nfi\n"
              },
              {
                "name": "Upload preflight artifacts",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "bridge-preflight",
                  "path": "_headers\n_redirects\nnetlify.toml\n"
                }
              }
            ]
          },
          "netlify-preview": {
            "needs": "preflight",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Netlify (defer to integration)",
                "run": "echo \"Netlify will pick up the PR with validated artifacts.\""
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge-runtime-local.yml",
      "name": "BRH Build & Publish",
      "config": {
        "name": "BRH Build & Publish",
        "true": {
          "push": {
            "branches": [
              "main"
            ],
            "paths": [
              "bridge_backend/**",
              ".github/workflows/bridge-runtime-local.yml"
            ]
          }
        },
        "permissions": {
          "contents": "read",
          "packages": "write"
        },
        "jobs": {
          "build": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Log in to GHCR",
                "run": "echo \"${{ secrets.GITHUB_TOKEN }}\" | docker login ghcr.io -u ${{ github.actor }} --password-stdin"
              },
              {
                "name": "Build backend image",
                "run": "docker build -t ghcr.io/${{ github.repository_owner }}/sr-aibridge-backend:latest -f bridge_backend/Dockerfile . || echo \"Build failed or skipped\"\ndocker push ghcr.io/${{ github.repository_owner }}/sr-aibridge-backend:latest || echo \"Push failed or skipped\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "example-sovereign-ci.yml",
      "name": "Example - Sovereign CI/CD",
      "config": {
        "name": "Example - Sovereign CI/CD",
        "true": {
          "push": {
            "branches": [
              "main",
              "develop"
            ]
          },
          "pull_request": null,
          "workflow_dispatch": null
        },
        "jobs": {
          "analyze-and-route": {
            "name": "Analyze Workflow Routing",
            "runs-on": "ubuntu-latest",
            "outputs": {
              "optimal_runner": "${{ steps.routing.outputs.runner }}",
              "estimated_minutes": "${{ steps.routing.outputs.minutes }}"
            },
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Determine optimal routing",
                "id": "routing",
                "run": "# Check if self-hosted runner is available\nif [ -f .github/self-hosted-runner.json ]; then\n  echo \"runner=self-hosted\" >> $GITHUB_OUTPUT\nelse\n  echo \"runner=ubuntu-latest\" >> $GITHUB_OUTPUT\nfi\necho \"minutes=15\" >> $GITHUB_OUTPUT\n"
              }
            ]
          },
          "test-backend": {
            "name": "Backend Tests (Self-Hosted)",
            "needs": "analyze-and-route",
            "runs-on": "${{ needs.analyze-and-route.outputs.optimal_runner }}",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11",
                  "cache": "pip"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install -r requirements.txt\n"
              },
              {
                "name": "Run backend tests",
                "run": "cd bridge_backend\npython -m pytest tests/ -v\n"
              },
              {
                "name": "Record usage (optional - for tracking)",
                "if": "always()",
                "run": "if [ \"${{ needs.analyze-and-route.outputs.optimal_runner }}\" == \"self-hosted\" ]; then\n  echo \"\u2705 Ran on self-hosted runner - Zero cost\"\n  echo \"\ud83d\udcca Estimated savings: \\$0.04 (5 minutes @ \\$0.008/min)\"\nelse\n  echo \"\ud83d\udcca Used GitHub Actions: 5 minutes\"\nfi\n"
              }
            ]
          },
          "build-frontend": {
            "name": "Frontend Build (Self-Hosted)",
            "needs": "analyze-and-route",
            "runs-on": "${{ needs.analyze-and-route.outputs.optimal_runner }}",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": 20,
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Install dependencies",
                "run": "cd bridge-frontend\nnpm ci\n"
              },
              {
                "name": "Build",
                "run": "cd bridge-frontend\nnpm run build\n"
              },
              {
                "name": "Upload build artifacts",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "frontend-build",
                  "path": "bridge-frontend/dist/",
                  "retention-days": 7
                }
              },
              {
                "name": "Record usage",
                "if": "always()",
                "run": "if [ \"${{ needs.analyze-and-route.outputs.optimal_runner }}\" == \"self-hosted\" ]; then\n  echo \"\u2705 Build completed on self-hosted runner\"\n  echo \"\ud83d\udcca Estimated savings: \\$0.024 (3 minutes @ \\$0.008/min)\"\nfi\n"
              }
            ]
          },
          "deploy-preview": {
            "name": "Deploy Preview (Netlify Free Tier)",
            "needs": [
              "test-backend",
              "build-frontend"
            ],
            "if": "github.event_name == 'pull_request'",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Download build artifacts",
                "uses": "actions/download-artifact@v4",
                "with": {
                  "name": "frontend-build",
                  "path": "bridge-frontend/dist/"
                }
              },
              {
                "name": "Deploy to Netlify (Free Tier)",
                "uses": "nwtgck/actions-netlify@v3.0",
                "with": {
                  "publish-dir": "bridge-frontend/dist",
                  "production-deploy": false,
                  "deploy-message": "Preview deploy for PR #${{ github.event.number }}"
                },
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
                }
              },
              {
                "name": "Record usage",
                "run": "echo \"\ud83d\udcca Netlify deploy used Netlify's free tier minutes\"\necho \"\u2705 No GitHub Actions minutes consumed for actual deploy\"\n"
              }
            ]
          },
          "deploy-production": {
            "name": "Deploy Production (Render Free Tier)",
            "needs": [
              "test-backend",
              "build-frontend"
            ],
            "if": "github.ref == 'refs/heads/main' && github.event_name == 'push'",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Trigger Render Deploy",
                "run": "if [ -n \"${{ secrets.RENDER_DEPLOY_HOOK }}\" ]; then\n  curl -X POST \"${{ secrets.RENDER_DEPLOY_HOOK }}\"\n  echo \"\u2705 Triggered Render deploy using free tier\"\n  echo \"\ud83d\udcca Build happens on Render (free 750 hours/month)\"\nelse\n  echo \"\u26a0\ufe0f  RENDER_DEPLOY_HOOK not configured\"\nfi\n"
              }
            ]
          },
          "report-costs": {
            "name": "Cost Report",
            "needs": [
              "test-backend",
              "build-frontend",
              "deploy-preview",
              "deploy-production"
            ],
            "if": "always()",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install pyyaml"
              },
              {
                "name": "Generate cost report",
                "run": "echo \"========================================\"\necho \"\ud83d\udcb0 WORKFLOW COST REPORT\"\necho \"========================================\"\necho \"\"\necho \"Jobs executed:\"\necho \"  - analyze-and-route: 1 min (GitHub)\"\necho \"  - test-backend: 5 min (${{ needs.analyze-and-route.outputs.optimal_runner }})\"\necho \"  - build-frontend: 3 min (${{ needs.analyze-and-route.outputs.optimal_runner }})\"\necho \"  - deploy: 1 min (Netlify/Render free tier)\"\necho \"\"\n\nif [ \"${{ needs.analyze-and-route.outputs.optimal_runner }}\" == \"self-hosted\" ]; then\n  echo \"\u2705 Total GitHub Actions cost: \\$0.016 (2 lightweight jobs)\"\n  echo \"\u2705 Savings from self-hosted: \\$0.064 (8 minutes avoided)\"\n  echo \"\ud83d\udcca Total savings: 80% cost reduction\"\nelse\n  echo \"\ud83d\udcca Total GitHub Actions cost: \\$0.080 (10 minutes)\"\n  echo \"\u2139\ufe0f  Tip: Set up self-hosted runner for zero cost\"\nfi\necho \"\"\necho \"========================================\"\n"
              },
              {
                "name": "Run cost analysis tools (if available)",
                "continue-on-error": true,
                "run": "if [ -f .github/forge_token_engine/cost_bypass.py ]; then\n  python .github/forge_token_engine/cost_bypass.py --report || true\nfi\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge-sync.yml",
      "name": "Bridge Sync Feedback",
      "config": {
        "name": "Bridge Sync Feedback",
        "true": {
          "workflow_dispatch": null,
          "repository_dispatch": {
            "types": [
              "bridge-deploy"
            ]
          }
        },
        "jobs": {
          "bridge-feedback": {
            "runs-on": "ubuntu-latest",
            "permissions": {
              "contents": "read",
              "issues": "write",
              "pull-requests": "write"
            },
            "steps": [
              {
                "name": "Checkout",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Parse Bridge Payload",
                "run": "echo \"Bridge Deploy received from Netlify\"\necho \"Payload: ${{ toJson(github.event.client_payload) }}\"\n"
              },
              {
                "name": "Post Comment to PR",
                "if": "${{ github.event.client_payload.pull_request_number }}",
                "uses": "actions/github-script@v7",
                "with": {
                  "github-token": "${{ secrets.GITHUB_TOKEN }}",
                  "script": "const pr = github.event.client_payload.pull_request_number;\nconst msg = github.event.client_payload.message || \"Bridge Deploy event received \u2705\";\nawait github.rest.issues.createComment({\n  ...context.repo,\n  issue_number: pr,\n  body: `\ud83d\udd17 **Bridge Sync Update**\\n${msg}\\n\\n_Triggered by SR-AIBridge webhook_`\n});\n"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "netlify_validation.yml",
      "name": "Netlify Validation (Umbra v1.9.7e)",
      "config": {
        "name": "Netlify Validation (Umbra v1.9.7e)",
        "true": {
          "pull_request": {
            "paths": [
              "netlify.toml",
              "_headers",
              "_redirects",
              "scripts/netlify_build.sh",
              "scripts/validate_netlify.py"
            ]
          },
          "push": {
            "branches": [
              "main",
              "release/**"
            ],
            "paths": [
              "netlify.toml",
              "_headers",
              "_redirects"
            ]
          },
          "workflow_dispatch": null
        },
        "permissions": {
          "contents": "read"
        },
        "jobs": {
          "validate-netlify": {
            "runs-on": "ubuntu-latest",
            "name": "Validate Netlify Configuration",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Run Netlify Validator",
                "id": "validate",
                "run": "echo \"\ud83d\udd0d Running Netlify Configuration Validator v1.9.7e...\"\npython3 scripts/validate_netlify.py\n"
              },
              {
                "name": "Record to Umbra Memory (on failure)",
                "if": "failure()",
                "continue-on-error": true,
                "run": "echo \"\ud83d\udcdd Recording validation failure to Umbra Memory...\"\npython3 - <<'PYTHON'\nimport os, json, sys\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\n# Create Umbra memory entry for failed validation\nmemory_dir = Path(\"vault/umbra\")\nmemory_dir.mkdir(parents=True, exist_ok=True)\n\nentry = {\n  \"id\": f\"netlify_validation_{int(datetime.now(timezone.utc).timestamp() * 1000)}\",\n  \"timestamp\": datetime.now(timezone.utc).isoformat(),\n  \"category\": \"netlify_validation\",\n  \"data\": {\n    \"event_type\": \"ci_validation\",\n    \"intent\": \"repair\",\n    \"workflow\": os.getenv(\"GITHUB_WORKFLOW\"),\n    \"run_id\": os.getenv(\"GITHUB_RUN_ID\"),\n    \"ref\": os.getenv(\"GITHUB_REF\")\n  },\n  \"result\": {\n    \"status\": \"failed\",\n    \"source\": \"ci_workflow\"\n  },\n  \"certified\": False\n}\n\n# Append to memory file if it exists, otherwise create new\nmemory_file = memory_dir / \"ci_validation_memory.json\"\nif memory_file.exists():\n  data = json.loads(memory_file.read_text())\n  data.setdefault(\"experiences\", []).append(entry)\nelse:\n  data = {\n    \"version\": \"1.9.7e\",\n    \"updated_at\": datetime.now(timezone.utc).isoformat(),\n    \"experiences\": [entry]\n  }\n\nmemory_file.write_text(json.dumps(data, indent=2))\nprint(f\"\u2705 Recorded validation failure to {memory_file}\")\nPYTHON\n"
              },
              {
                "name": "Upload validation results",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "netlify-validation-results",
                  "path": "netlify.toml\n_headers\n_redirects\nvault/umbra/ci_validation_memory.json\n",
                  "if-no-files-found": "ignore"
                }
              },
              {
                "name": "Validation Summary",
                "if": "success()",
                "run": "echo \"\u2705 Netlify configuration validation passed!\"\necho \"\ud83c\udf10 All rules are syntactically correct\"\necho \"\ud83d\udd12 RBAC: Ready for Admiral/Captain approval\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "build_triage_netlify.yml",
      "name": "Build Triage (Netlify)",
      "config": {
        "name": "Build Triage (Netlify)",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "15 */6 * * *"
            }
          ]
        },
        "permissions": {
          "contents": "read"
        },
        "jobs": {
          "build-triage": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "22",
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Cache Playwright browsers",
                "uses": "actions/cache@v4",
                "with": {
                  "path": "~/.cache/ms-playwright",
                  "key": "${{ runner.os }}-playwright-${{ hashFiles('bridge-frontend/package-lock.json') }}",
                  "restore-keys": "${{ runner.os }}-playwright-\n"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps chromium\nnpx playwright install chromium\n"
              },
              {
                "name": "Install & Dry Build (monorepo aware)",
                "env": {
                  "CI": false
                },
                "run": "cd bridge-frontend\nnpm ci || npm install\nnpm run build --if-present || echo \"::warning ::build script missing\"\ntest -d dist || echo \"::error ::No dist folder created\"\n"
              },
              {
                "name": "Emit Build Artifact Summary",
                "run": "python3 - <<'PY'\nimport json, os, pathlib\nout = {\n  \"has_dist\": os.path.isdir(\"bridge-frontend/dist\"),\n  \"size_kb\": sum((f.stat().st_size for f in pathlib.Path(\"bridge-frontend/dist\").rglob(\"*\") if f.is_file()), 0)//1024 if os.path.isdir(\"bridge-frontend/dist\") else 0,\n  \"missing_scripts\": not (pathlib.Path(\"bridge-frontend/package.json\").read_text().find('\"build\"')>0)\n}\npathlib.Path(\"bridge_backend/diagnostics\").mkdir(parents=True, exist_ok=True)\n(pathlib.Path(\"bridge_backend/diagnostics\")/\"build_triage_report.json\").write_text(json.dumps(out, indent=2))\nprint(json.dumps(out, indent=2))\nPY\n"
              },
              {
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "build_triage_report",
                  "path": "bridge_backend/diagnostics/build_triage_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "firewall-bypass.yml",
      "name": "Browser Dependency Resolution (Firewall Bypass)",
      "config": {
        "name": "Browser Dependency Resolution (Firewall Bypass)",
        "true": {
          "workflow_call": {
            "inputs": {
              "skip-chromium": {
                "description": "Skip Chromium installation",
                "required": false,
                "type": "boolean",
                "default": false
              },
              "node-version": {
                "description": "Node.js version to use",
                "required": false,
                "type": "string",
                "default": "20"
              }
            }
          }
        },
        "jobs": {
          "resolve-browser-deps": {
            "name": "Resolve Browser Dependencies",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Configure Alternative Browser Sources",
                "if": "${{ !inputs.skip-chromium }}",
                "run": "echo \"\ud83c\udf10 Configuring browser dependencies for firewall-restricted environment...\"\n\n# Install Playwright system dependencies\necho \"\ud83d\udce6 Installing Playwright browser dependencies...\"\nnpx playwright install-deps || echo \"\u26a0\ufe0f Playwright deps install failed, continuing...\"\n\n# Install Chromium via Playwright (bypasses firewall restrictions)\necho \"\ud83d\udd27 Installing Chromium browser...\"\nnpx playwright install chromium || echo \"\u26a0\ufe0f Chromium install failed, continuing...\"\n\n# Set browser executable path for tools that need it\nCHROMIUM_PATH=$(which chromium 2>/dev/null || which chromium-browser 2>/dev/null || echo \"\")\nif [ -n \"$CHROMIUM_PATH\" ]; then\n  echo \"BROWSER_EXECUTABLE_PATH=$CHROMIUM_PATH\" >> $GITHUB_ENV\n  echo \"\u2705 Browser executable found at: $CHROMIUM_PATH\"\nelse\n  echo \"\u26a0\ufe0f Chromium not found in PATH, tools may use system default\"\nfi\n"
              },
              {
                "name": "Set Puppeteer Environment Variables",
                "run": "echo \"\ud83d\udd27 Configuring Puppeteer to skip download...\"\necho \"PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true\" >> $GITHUB_ENV\necho \"PUPPETEER_SKIP_DOWNLOAD=true\" >> $GITHUB_ENV\n\n# Try to find Chrome/Chromium for Puppeteer\nCHROME_PATH=$(which chromium 2>/dev/null || which chromium-browser 2>/dev/null || which google-chrome 2>/dev/null || echo \"\")\nif [ -n \"$CHROME_PATH\" ]; then\n  echo \"CHROME_BIN=$CHROME_PATH\" >> $GITHUB_ENV\n  echo \"PUPPETEER_EXECUTABLE_PATH=$CHROME_PATH\" >> $GITHUB_ENV\n  echo \"\u2705 Chrome/Chromium configured for Puppeteer: $CHROME_PATH\"\nelse\n  echo \"\u26a0\ufe0f Chrome/Chromium not found, Puppeteer may fail if required\"\nfi\n"
              },
              {
                "name": "Set Playwright Environment Variables",
                "run": "echo \"\ud83d\udd27 Configuring Playwright...\"\necho \"PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=false\" >> $GITHUB_ENV\necho \"PLAYWRIGHT_BROWSERS_PATH=0\" >> $GITHUB_ENV\necho \"\u2705 Playwright configured to use system browsers\"\n"
              },
              {
                "name": "Verify Browser Installation",
                "if": "${{ !inputs.skip-chromium }}",
                "run": "echo \"\ud83d\udd0d Verifying browser installation...\"\n\n# Check if Chromium is available\nif command -v chromium &> /dev/null || command -v chromium-browser &> /dev/null; then\n  CHROMIUM_VERSION=$(chromium --version 2>/dev/null || chromium-browser --version 2>/dev/null || echo \"Unknown\")\n  echo \"\u2705 Chromium installed: $CHROMIUM_VERSION\"\nelse\n  echo \"\u26a0\ufe0f Chromium not found in system PATH\"\nfi\n\n# Check Playwright browsers\nif npx playwright --version &> /dev/null; then\n  PLAYWRIGHT_VERSION=$(npx playwright --version 2>/dev/null || echo \"Unknown\")\n  echo \"\u2705 Playwright available: $PLAYWRIGHT_VERSION\"\nelse\n  echo \"\u26a0\ufe0f Playwright not available\"\nfi\n\necho \"\u2705 Browser dependency resolution complete\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "budget-monitor.yml",
      "name": "Budget Monitor",
      "config": {
        "name": "Budget Monitor",
        "true": {
          "schedule": [
            {
              "cron": "0 12 * * *"
            }
          ],
          "workflow_dispatch": {
            "inputs": {
              "force_check": {
                "description": "Force budget check even if recently run",
                "required": false,
                "default": "false"
              }
            }
          }
        },
        "jobs": {
          "monitor-budget": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Run budget monitor",
                "id": "monitor",
                "run": "python .github/forge_token_engine/budget_monitor.py\n",
                "continue-on-error": true
              },
              {
                "name": "Check financial rescue status",
                "id": "rescue",
                "run": "python .github/forge_token_engine/financial_rescue.py\n"
              },
              {
                "name": "Upload monitoring logs",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "budget-monitoring-logs",
                  "path": ".github/forge_token_engine/monitor_log.json\n.github/forge_token_engine/cost_log.json\n.github/forge_token_engine/financial_rescue_config.json\n",
                  "retention-days": 30
                }
              },
              {
                "name": "Create issue on budget alert",
                "if": "steps.monitor.outcome == 'failure'",
                "uses": "actions/github-script@v7",
                "with": {
                  "script": "const fs = require('fs');\n\n// Read monitoring log to get alert details\nlet alertMessage = 'Budget monitoring detected an issue. Please check the logs.';\n\ntry {\n  const monitorLog = JSON.parse(fs.readFileSync('.github/forge_token_engine/monitor_log.json', 'utf8'));\n  const lastAlert = monitorLog.alerts_sent[monitorLog.alerts_sent.length - 1];\n  \n  if (lastAlert) {\n    alertMessage = `**Alert Type:** ${lastAlert.type}\\n\\n`;\n    alertMessage += `**Details:**\\n\\`\\`\\`json\\n${JSON.stringify(lastAlert.details, null, 2)}\\n\\`\\`\\`\\n\\n`;\n    alertMessage += `**Timestamp:** ${lastAlert.timestamp}`;\n  }\n} catch (e) {\n  console.log('Could not read monitoring log:', e);\n}\n\n// Check if an issue already exists for this month\nconst issues = await github.rest.issues.listForRepo({\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  labels: 'budget-alert',\n  state: 'open'\n});\n\nconst today = new Date();\nconst monthYear = `${today.getFullYear()}-${String(today.getMonth() + 1).padStart(2, '0')}`;\nconst existingIssue = issues.data.find(issue => \n  issue.title.includes(monthYear)\n);\n\nif (!existingIssue) {\n  // Create new issue\n  await github.rest.issues.create({\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    title: `\ud83d\udea8 Budget Alert - ${monthYear}`,\n    body: `# Budget Monitoring Alert\\n\\n${alertMessage}\\n\\n## Actions Taken\\n\\nThe financial rescue system has automatically activated protection mechanisms.\\n\\n## Next Steps\\n\\n1. Review current spending in [Actions usage](../../actions)\\n2. Check financial rescue status: \\`python .github/forge_token_engine/financial_rescue.py\\`\\n3. Run emergency containment if needed: \\`python .github/emergency_cost_containment.py\\`\\n\\n## Documentation\\n\\nSee [Financial Rescue README](.github/forge_token_engine/FINANCIAL_RESCUE_README.md) for details.`,\n    labels: ['budget-alert', 'automated']\n  });\n} else {\n  // Update existing issue with new alert\n  await github.rest.issues.createComment({\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    issue_number: existingIssue.number,\n    body: `## New Budget Alert\\n\\n${alertMessage}`\n  });\n}\n"
                }
              },
              {
                "name": "Summary",
                "if": "always()",
                "run": "echo \"## Budget Monitoring Summary\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Try to extract key metrics\nif [ -f .github/forge_token_engine/financial_rescue_config.json ]; then\n  SPEND=$(python -c \"import json; print(json.load(open('.github/forge_token_engine/financial_rescue_config.json'))['current_month_spend'])\")\n  LIMIT=$(python -c \"import json; print(json.load(open('.github/forge_token_engine/financial_rescue_config.json'))['budget_limit'])\")\n  REMAINING=$(python -c \"import json; config = json.load(open('.github/forge_token_engine/financial_rescue_config.json')); print(config['budget_limit'] - config['current_month_spend'])\")\n  \n  echo \"- **Current Spend:** \\$$SPEND\" >> $GITHUB_STEP_SUMMARY\n  echo \"- **Budget Limit:** \\$$LIMIT\" >> $GITHUB_STEP_SUMMARY\n  echo \"- **Remaining:** \\$$REMAINING\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"Budget monitoring completed. Check logs for details.\" >> $GITHUB_STEP_SUMMARY\n"
              }
            ]
          },
          "notify": {
            "runs-on": "ubuntu-latest",
            "needs": "monitor-budget",
            "if": "failure()",
            "steps": [
              {
                "name": "Notification placeholder",
                "run": "echo \"Budget alert triggered. Configure notifications here.\"\n# Examples:\n# - Send to Slack\n# - Send email\n# - Post to Discord\n# - Create PagerDuty incident\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "deploy_triage.yml",
      "name": "Bridge Deploy Path Verification",
      "config": {
        "name": "Bridge Deploy Path Verification",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": null,
          "workflow_dispatch": null
        },
        "jobs": {
          "verify-deploy-paths": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Run Deploy Path Triage Engine",
                "run": "python3 bridge_backend/tools/triage/deploy_path_triage.py"
              },
              {
                "name": "Upload Diagnostics",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "deploy_path_triage_report",
                  "path": "bridge_backend/diagnostics/deploy_path_triage_report.json"
                }
              },
              {
                "name": "Upload Netlify Health Badge",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "netlify_health_badge",
                  "path": "docs/BADGE_DEPLOY_STATUS.md"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "healer_net.yml",
      "name": "Healer-Net Global Diagnostics",
      "config": {
        "name": "Healer-Net Global Diagnostics",
        "true": {
          "schedule": [
            {
              "cron": "0 */6 * * *"
            }
          ],
          "workflow_dispatch": null,
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "healernet": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Initialize Healer-Net",
                "run": "echo \"\ud83c\udf10 Starting unified triage and harmony sync...\""
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install requests"
              },
              {
                "name": "Run Firewall Harmony Check",
                "run": "echo \"\ud83d\udd25 Running Firewall Harmony diagnostics...\"\npython3 bridge_backend/tools/firewall_intel/chromium_probe.py || true\n"
              },
              {
                "name": "Run Endpoint Triage",
                "env": {
                  "BRIDGE_BASE_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "echo \"\ud83e\ude7a Running Endpoint Triage...\"\ncd bridge_backend\npython3 scripts/endpoint_triage.py --manual || true\n"
              },
              {
                "name": "Run API Triage",
                "env": {
                  "BRIDGE_BASE_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "echo \"\ud83e\uddec Running API Triage...\"\ncd bridge_backend\npython3 scripts/api_triage.py --manual || true\n"
              },
              {
                "name": "Collect Health Data",
                "run": "python3 bridge_backend/tools/health/healer_net_probe.py"
              },
              {
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "healer_net_report",
                  "path": "healer_net_report.json",
                  "if-no-files-found": "ignore"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "triage-preseed.yml",
      "name": "Triage Pre-Seed",
      "config": {
        "name": "Triage Pre-Seed",
        "true": {
          "workflow_dispatch": null
        },
        "jobs": {
          "preseed": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "cd bridge_backend\npip install requests\n"
              },
              {
                "name": "Generate Baseline Reports",
                "run": "cd bridge_backend\npython3 scripts/triage_preseed.py\n"
              },
              {
                "name": "Upload Baseline to Bridge",
                "run": "curl -X POST \"${{ secrets.BRIDGE_URL }}/api/diagnostics\" \\\n  -H \"Content-Type: application/json\" \\\n  -d @bridge_backend/unified_timeline.json || echo \"Bridge notification skipped (URL not configured)\"\n"
              },
              {
                "name": "Upload Artifacts",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "preseed-reports",
                  "path": "bridge_backend/endpoint_report.json\nbridge_backend/api_triage_report.json\nbridge_backend/hooks_triage_report.json\nbridge_backend/ci_cd_report.json\nbridge_backend/unified_timeline.json\n",
                  "retention-days": 7
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_autodeploy.yml",
      "name": "Bridge Auto-Deploy Mode (DISABLED - Use deploy.yml)",
      "config": {
        "name": "Bridge Auto-Deploy Mode (DISABLED - Use deploy.yml)",
        "true": {
          "workflow_dispatch": null
        },
        "jobs": {
          "bridge-autodeploy": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Node.js 20",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20",
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install Dependencies",
                "run": "cd bridge-frontend\nnpm ci --legacy-peer-deps || npm install --legacy-peer-deps\n"
              },
              {
                "name": "Build Frontend",
                "run": "cd bridge-frontend\nnpm run build\n"
              },
              {
                "name": "Setup Forge Dominion",
                "id": "forge",
                "uses": "./.github/actions/forge-dominion-setup",
                "with": {
                  "forge-dominion-root": "${{ secrets.FORGE_DOMINION_ROOT }}",
                  "providers": "netlify"
                }
              },
              {
                "name": "Notify Deployment Start",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform netlify \\\n  --event-type start \\\n  --status deploying \\\n  --branch main \\\n  --message \"Auto-deploy via Bridge Auto-Deploy Mode v1.9.7s (Forge Dominion)\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Verify Backend Health",
                "timeout-minutes": 5,
                "run": "echo \"\ud83d\udd0d Verifying backend health...\"\nBACKEND_URL=\"${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}\"\nresponse=$(curl -f -s \"$BACKEND_URL/api/health\" || echo \"FAILED\")\nif [[ \"$response\" == \"FAILED\" ]]; then\n  echo \"\u26a0\ufe0f Backend health check failed or endpoint unavailable\"\n  echo \"Note: This is expected if using sovereign deployment without legacy backend\"\nelse\n  echo \"\u2705 Backend is healthy\"\nfi\n"
              },
              {
                "name": "Generate Sync Badge",
                "run": "python3 bridge_backend/scripts/generate_sync_badge.py\n"
              },
              {
                "name": "Deploy to Netlify (Forge Dominion)",
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ steps.forge.outputs.netlify-token }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
                },
                "run": "npm install -g netlify-cli\ncd bridge-frontend\necho \"\ud83d\udf02 Deploying with Forge Dominion ephemeral token...\"\nnetlify deploy --prod --dir=dist --message=\"Auto-redeploy via Bridge Auto-Deploy Mode v1.9.7s (Sovereign)\"\n"
              },
              {
                "name": "Notify Deployment Success",
                "if": "success()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform netlify \\\n  --event-type success \\\n  --status deployed \\\n  --branch main \\\n  --deploy-url \"https://sr-aibridge.netlify.app\" \\\n  --message \"Deployment successful (Forge Dominion)\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Notify Deployment Failure",
                "if": "failure()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform netlify \\\n  --event-type failure \\\n  --status failed \\\n  --branch main \\\n  --message \"Deployment failed\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Report to Diagnostics",
                "run": "python3 bridge_backend/scripts/report_bridge_event.py --status AUTODEPLOY_OK || echo \"\u26a0\ufe0f Diagnostics reporting skipped\"\n"
              },
              {
                "name": "Deployment Summary",
                "run": "echo \"=== Bridge Auto-Deploy Summary (Forge Dominion) ===\"\necho \"\u2705 Frontend built successfully\"\necho \"\u2705 Backend health verified\"\necho \"\u2705 Sync badge updated\"\necho \"\ud83d\udf02 Forge Dominion: ${{ steps.forge.outputs.tokens-minted }} tokens minted\"\necho \"\u2705 Deployed to Netlify (ephemeral token)\"\necho \"===================================================\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "deploy.yml",
      "name": "Build & Deploy SR-AIbridge",
      "config": {
        "name": "Build & Deploy SR-AIbridge",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": {}
        },
        "jobs": {
          "predictive-deploy": {
            "name": "Predictive Deploy Pipeline",
            "runs-on": "ubuntu-latest",
            "permissions": {
              "contents": "read"
            },
            "steps": [
              {
                "name": "Checkout",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install backend deps",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt\n"
              },
              {
                "name": "Predictive pipeline (simulate \u2192 certify \u2192 deploy with fallback)",
                "env": {
                  "ENGINES_ENABLE_TRUE": "true",
                  "RBAC_ENFORCED": "true",
                  "TRUTH_CERTIFICATION": "true",
                  "GENESIS_MODE": "enabled"
                },
                "run": "python -m bridge_backend.cli.deployctl predictive --ref $GITHUB_SHA\n"
              },
              {
                "name": "Upload Hydra artifacts (headers/redirects)",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "hydra-artifacts",
                  "path": "public/_headers\npublic/_redirects\nnetlify.toml\n"
                }
              }
            ]
          },
          "deploy-frontend": {
            "name": "Deploy Frontend to Netlify",
            "runs-on": "ubuntu-latest",
            "needs": [
              "predictive-deploy"
            ],
            "if": "success() || github.event_name == 'workflow_dispatch'",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20",
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install dependencies",
                "run": "cd bridge-frontend && npm ci"
              },
              {
                "name": "Build frontend",
                "run": "cd bridge-frontend && npm run build",
                "env": {
                  "CI": false,
                  "REACT_APP_API_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}"
                }
              },
              {
                "name": "Notify Netlify Deployment Start",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform netlify \\\n  --event-type start \\\n  --status deploying \\\n  --branch ${{ github.ref_name }} \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Deploy from GitHub Actions\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Deploy to Netlify",
                "uses": "nwtgck/actions-netlify@v3.0",
                "with": {
                  "publish-dir": "./bridge-frontend/dist",
                  "production-branch": "main",
                  "github-token": "${{ secrets.GITHUB_TOKEN }}",
                  "deploy-message": "Deploy from GitHub Actions",
                  "enable-pull-request-comment": true,
                  "enable-commit-comment": true
                },
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
                },
                "timeout-minutes": 10
              },
              {
                "name": "Notify Netlify Deployment Success",
                "if": "success()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform netlify \\\n  --event-type success \\\n  --status deployed \\\n  --branch ${{ github.ref_name }} \\\n  --commit-sha ${{ github.sha }} \\\n  --deploy-url \"https://sr-aibridge.netlify.app\" \\\n  --message \"Deployment successful\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Notify Netlify Deployment Failure",
                "if": "failure()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform netlify \\\n  --event-type failure \\\n  --status failed \\\n  --branch ${{ github.ref_name }} \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Deployment failed\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Notify Bridge Diagnostics",
                "if": "success() && github.ref == 'refs/heads/main'",
                "run": "BRIDGE_URL=\"${{ secrets.BRIDGE_URL || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com' }}\"\ncurl -X POST \"$BRIDGE_URL/api/diagnostics\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"type\": \"DEPLOYMENT_SUCCESS\",\n    \"status\": \"success\",\n    \"source\": \"GitHubAction\",\n    \"meta\": {\n      \"environment\": \"production\",\n      \"timestamp\": \"'\"$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\"'\"\n    }\n  }' || echo \"Diagnostics notification failed (non-critical)\"\n"
              }
            ]
          },
          "deploy-backend": {
            "name": "Trigger Backend Deployment",
            "runs-on": "ubuntu-latest",
            "if": "github.ref == 'refs/heads/main'",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Validate backend configuration",
                "run": "echo \"Validating backend setup...\"\ncd bridge_backend\npython3 -m py_compile main.py\npython3 -m py_compile self_test.py\necho \"\u2705 Backend Python files validated\"\n"
              },
              {
                "name": "Notify Render Deployment Start",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform render \\\n  --event-type start \\\n  --status deploying \\\n  --branch main \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Trigger Render deployment\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Trigger Render deployment",
                "run": "if [ -n \"${{ secrets.RENDER_DEPLOY_HOOK }}\" ]; then\n  echo \"Triggering Render deployment...\"\n  curl -X POST \"${{ secrets.RENDER_DEPLOY_HOOK }}\"\n  echo \"\u2705 Render deployment triggered\"\nelse\n  echo \"\u26a0\ufe0f RENDER_DEPLOY_HOOK not configured - skipping deployment\"\n  echo \"Note: Render will auto-deploy on push to main branch\"\nfi\n"
              },
              {
                "name": "Notify Render Deployment Success",
                "if": "success()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform backend \\\n  --event-type success \\\n  --status triggered \\\n  --branch main \\\n  --commit-sha ${{ github.sha }} \\\n  --deploy-url \"${{ secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com' }}\" \\\n  --message \"Backend deployment triggered successfully\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Notify Backend Deployment Failure",
                "if": "failure()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform backend \\\n  --event-type failure \\\n  --status failed \\\n  --branch main \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Failed to trigger Render deployment\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              }
            ]
          },
          "verify-build": {
            "name": "Verify Complete Build",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Notify GitHub Build Start",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform github \\\n  --event-type start \\\n  --status verifying \\\n  --branch ${{ github.ref_name }} \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Build verification started\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Setup Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20",
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install frontend dependencies",
                "run": "cd bridge-frontend && npm ci"
              },
              {
                "name": "Install backend dependencies",
                "run": "cd bridge_backend && pip install -r requirements.txt"
              },
              {
                "name": "Test frontend build",
                "run": "cd bridge-frontend && npm run build",
                "env": {
                  "CI": false
                }
              },
              {
                "name": "Test backend syntax",
                "run": "cd bridge_backend\npython3 -m py_compile main.py\npython3 -m py_compile self_test.py\npython3 -c \"import main; print('\u2705 Backend imports successfully')\"\n"
              },
              {
                "name": "Verify self-test script",
                "run": "cd bridge_backend\npython3 self_test.py --help\necho \"\u2705 Self-test script is executable\"\n"
              },
              {
                "name": "Notify GitHub Build Success",
                "if": "success()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform github \\\n  --event-type success \\\n  --status verified \\\n  --branch ${{ github.ref_name }} \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Build verification completed successfully\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              },
              {
                "name": "Notify GitHub Build Failure",
                "if": "failure()",
                "run": "python3 bridge_backend/utils/deployment_publisher.py \\\n  --platform github \\\n  --event-type failure \\\n  --status failed \\\n  --branch ${{ github.ref_name }} \\\n  --commit-sha ${{ github.sha }} \\\n  --message \"Build verification failed\" || echo \"\u26a0\ufe0f Event notification skipped\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "repo-codex.yml",
      "name": "Repo Codex Compiler",
      "config": {
        "name": "Repo Codex Compiler",
        "true": {
          "push": {
            "branches": [
              "main"
            ],
            "paths": [
              "**/*.md",
              "**/*.yml",
              "**/*.yaml",
              "**/*.py"
            ]
          }
        },
        "jobs": {
          "build": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install pyyaml markdown\n"
              },
              {
                "name": "Build Repo Codex",
                "run": "python codex/compiler.py\npython codex/markdown_compiler.py\npython codex/html_compiler.py\n"
              },
              {
                "name": "Upload artifacts",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "repo-book",
                  "path": "codex/output/"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "build-deploy-triage.yml",
      "name": "\ud83d\udd01 Build & Deploy Triage (DISABLED - Use deploy.yml)",
      "config": {
        "name": "\ud83d\udd01 Build & Deploy Triage (DISABLED - Use deploy.yml)",
        "true": {
          "workflow_dispatch": null
        },
        "jobs": {
          "triage": {
            "name": "Validate \u2192 Build \u2192 Deploy \u2192 Notify",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "Setup Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "run": "pip install requests python-dotenv"
              },
              {
                "name": "\ud83d\udd0d Validate & Auto-Heal Env",
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}",
                  "RENDER_API_KEY": "${{ secrets.RENDER_API_KEY }}",
                  "RENDER_SERVICE_ID": "${{ secrets.RENDER_SERVICE_ID }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "python3 scripts/check_env_parity.py || (\n  python3 scripts/repair_netlify_env.py\n  python3 scripts/check_env_parity.py\n  python3 scripts/report_bridge_event.py\n)\n"
              },
              {
                "name": "\ud83e\uddf1 Build Frontend",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}",
                  "BRIDGE_SLACK_WEBHOOK": "${{ secrets.BRIDGE_SLACK_WEBHOOK }}"
                },
                "run": "cd bridge-frontend\nnpm ci\nnpm run build || (\n  echo \"\u274c Build failed \u2014 notifying Bridge\"\n  python3 ../scripts/report_bridge_event.py report_build_failure || true\n  exit 1\n)\necho \"\u2705 Build succeeded \u2014 notifying Bridge\"\npython3 ../scripts/report_bridge_event.py report_build_success\n"
              },
              {
                "name": "\ud83d\ude80 Deploy to Netlify",
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}",
                  "BRIDGE_SLACK_WEBHOOK": "${{ secrets.BRIDGE_SLACK_WEBHOOK }}"
                },
                "run": "npm install -g netlify-cli\necho \"\ud83d\ude80 Starting deployment...\"\nnetlify deploy --dir=bridge-frontend/dist --site=$NETLIFY_SITE_ID --prod || (\n  echo \"\u26a0\ufe0f Deploy failed \u2014 rolling back to previous successful version\"\n  python3 scripts/report_bridge_event.py report_deploy_failure || true\n  python3 scripts/netlify_rollback.py\n  exit 1\n)\n"
              },
              {
                "name": "\ud83d\udce1 Notify Bridge of Deploy Success",
                "if": "success()",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "python3 -c \"from scripts.report_bridge_event import report_deploy_success; report_deploy_success()\""
              },
              {
                "name": "\ud83d\udcca Generate CI/CD Triage Report",
                "if": "always()",
                "working-directory": "bridge_backend",
                "run": "if [ \"${{ job.status }}\" == \"success\" ]; then\n  python3 scripts/ci_cd_triage.py DEPLOYMENT_SUCCESS success\nelse\n  python3 scripts/ci_cd_triage.py DEPLOYMENT_FAILURE failed\nfi\n"
              },
              {
                "name": "\ud83d\udce4 Upload CI/CD Triage Report",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "ci-cd-triage-report",
                  "path": "bridge_backend/ci_cd_report.json",
                  "retention-days": 30
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "diagnostic-retention.yml",
      "name": "\ud83e\uddf9 Bridge Diagnostic Retention",
      "config": {
        "name": "\ud83e\uddf9 Bridge Diagnostic Retention",
        "true": {
          "schedule": [
            {
              "cron": "0 4 * * *"
            }
          ],
          "workflow_dispatch": null
        },
        "jobs": {
          "retention": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "run": "pip install requests"
              },
              {
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}",
                  "BRIDGE_SLACK_WEBHOOK": "${{ secrets.BRIDGE_SLACK_WEBHOOK }}"
                },
                "run": "python3 scripts/prune_diagnostics.py"
              }
            ]
          }
        }
      }
    },
    {
      "file": "env_autoheal.yml",
      "name": "Environment Auto-Repair & Verification",
      "config": {
        "name": "Environment Auto-Repair & Verification",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "autoheal": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install requests toml aiohttp"
              },
              {
                "name": "Validate Environment",
                "run": "python3 scripts/validate_env_setup.py"
              },
              {
                "name": "Validate Scanner Compliance",
                "run": "python3 scripts/validate_scanner_output.py"
              },
              {
                "name": "Run Environment Auto-Repair",
                "run": "python3 scripts/repair_netlify_env.py",
                "env": {
                  "NETLIFY_API_KEY": "${{ secrets.NETLIFY_API_KEY }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
                }
              },
              {
                "name": "Report Bridge Diagnostics",
                "run": "python3 scripts/report_bridge_event.py",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "endpoint-deepscan.yml",
      "name": "Endpoint DeepScan Triage",
      "config": {
        "name": "Endpoint DeepScan Triage",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "0 3 * * *"
            }
          ],
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "deep-scan": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Node",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": 20
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install Dependencies",
                "run": "npm ci || npm install",
                "working-directory": "bridge-frontend"
              },
              {
                "name": "\ud83e\udded Scan for Endpoint Definitions",
                "run": "echo \"\ud83d\udd0d Scanning repo for endpoint URLs and API routes...\"\ngrep -R \"https://\" bridge-frontend/src || echo \"\u26a0\ufe0f No hardcoded endpoints found\"\ngrep -R \"fetch(\" bridge-frontend/src || true\ngrep -R \"axios\" bridge-frontend/src || true\n"
              },
              {
                "name": "\ud83e\udde9 Verify Environment Parity",
                "run": "echo \"\ud83d\udd0e Checking environment variables consistency...\"\nnode -e \"\nconst keys=['VITE_API_BASE','REACT_APP_API_URL','PUBLIC_API_BASE','BRIDGE_API_URL'];\nlet missing=[];\nkeys.forEach(k=>{\n  if(!process.env[k]) missing.push(k);\n  else console.log(\\`\u2705 \\${k}: \\${process.env[k]}\\`);\n});\nif(missing.length>0){\n  console.error('\u26a0\ufe0f Missing keys:', missing.join(', '));\n  console.log('\u2705 Environment parity check complete (missing keys expected in CI)');\n} else {\n  console.log('\u2705 Environment parity verified');\n}\"\n"
              },
              {
                "name": "\ud83c\udf10 Endpoint Connectivity Test",
                "env": {
                  "VITE_API_BASE": "${{ secrets.VITE_API_BASE || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com/api' }}",
                  "REACT_APP_API_URL": "${{ secrets.REACT_APP_API_URL || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com/api' }}"
                },
                "run": "echo \"\ud83c\udf10 Testing live endpoints...\"\nfor endpoint in $VITE_API_BASE $REACT_APP_API_URL; do\n  if [ -n \"$endpoint\" ]; then\n    echo \"\ud83d\udd17 Testing $endpoint ...\"\n    code=$(curl -s -o /dev/null -w \"%{http_code}\" \"$endpoint\" || echo \"000\")\n    echo \"\u27a1\ufe0f  Response Code: $code\"\n    if [ \"$code\" -ne 200 ]; then\n      echo \"\u26a0\ufe0f Endpoint $endpoint returned code $code (expected if using sovereign deployment)\"\n    else\n      echo \"\u2705 Endpoint $endpoint reachable\"\n    fi\n  fi\ndone\n"
              },
              {
                "name": "\ud83e\uddf1 CORS Verification",
                "env": {
                  "VITE_API_BASE": "${{ secrets.VITE_API_BASE || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com/api' }}"
                },
                "run": "echo \"\ud83e\uddf1 Checking CORS headers...\"\ncurl -I -s $VITE_API_BASE | grep -i \"access-control-allow-origin\" || echo \"\u26a0\ufe0f No CORS headers detected (expected if endpoint unavailable)\"\n"
              },
              {
                "name": "\ud83d\udce1 Report DeepScan Results to Bridge",
                "if": "always()",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "echo \"\ud83d\udce1 Reporting DeepScan summary to Bridge...\"\nif [ -n \"$BRIDGE_URL\" ]; then\n  curl -X POST \"${{ secrets.BRIDGE_URL }}/api/diagnostics\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\n      \\\"type\\\": \\\"ENDPOINT_DEEPSCAN\\\",\n      \\\"status\\\": \\\"complete\\\",\n      \\\"source\\\": \\\"GitHubAction\\\",\n      \\\"meta\\\": {\n        \\\"timestamp\\\": \\\"$(date -u +%FT%TZ)\\\",\n        \\\"environment\\\": \\\"production\\\",\n        \\\"ci_context\\\": \\\"Netlify+Render Integration\\\",\n        \\\"notes\\\": \\\"Full endpoint and environment scan executed successfully.\\\"\n      }\n    }\" || echo \"\u26a0\ufe0f Failed to report to Bridge\"\nelse\n  echo \"\u26a0\ufe0f BRIDGE_URL not set, skipping report\"\nfi\n"
              },
              {
                "name": "\u2705 Final Status",
                "run": "echo \"\ud83d\udef0\ufe0f DeepScan completed successfully\""
              }
            ]
          }
        }
      }
    },
    {
      "file": "firewall_harmony.yml",
      "name": "Firewall Harmony",
      "config": {
        "name": "Firewall Harmony",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": null,
          "workflow_dispatch": null
        },
        "jobs": {
          "harmony": {
            "runs-on": "ubuntu-latest",
            "env": {
              "PUPPETEER_SKIP_DOWNLOAD": "true",
              "PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD": "true",
              "CHROMIUM_DOWNLOAD_ALLOWED": "false",
              "CHROMIUM_CHANNEL": "stable",
              "PUPPETEER_CACHE_DIR": "~/.cache/puppeteer",
              "PLAYWRIGHT_BROWSERS_PATH": "~/.cache/ms-playwright"
            },
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20",
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "uses": "actions/cache@v4",
                "with": {
                  "path": "~/.cache/puppeteer\n~/.cache/ms-playwright\n",
                  "key": "chromium-${{ runner.os }}-${{ hashFiles('bridge-frontend/package-lock.json') }}",
                  "restore-keys": "chromium-${{ runner.os }}-"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install deps",
                "run": "npm ci",
                "working-directory": "bridge-frontend"
              },
              {
                "name": "Run Chromium Guard",
                "run": "node scripts/chromium-guard.mjs",
                "working-directory": "bridge-frontend"
              },
              {
                "name": "Build project",
                "run": "npm run build",
                "working-directory": "bridge-frontend"
              },
              {
                "name": "Probe diagnostic",
                "run": "python3 bridge_backend/tools/firewall_intel/chromium_probe.py | tee chromium_probe.json"
              },
              {
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "chromium_probe",
                  "path": "chromium_probe.json"
                }
              },
              {
                "name": "Auto-Repair (Warm cache on fail)",
                "if": "failure()",
                "run": "echo \"\ud83d\udd25 Detected failed run \u2014 enabling cache-warm repair.\"\nexport CHROMIUM_DOWNLOAD_ALLOWED=true\nnode scripts/chromium-guard.mjs || true\necho \"\u2705 Repair completed; cache should now contain browsers.\"\n",
                "working-directory": "bridge-frontend"
              }
            ]
          }
        }
      }
    },
    {
      "file": "firewall_intel.yml",
      "name": "Firewall Intelligence - Nightly Scan",
      "config": {
        "name": "Firewall Intelligence - Nightly Scan",
        "true": {
          "schedule": [
            {
              "cron": "0 2 * * *"
            }
          ],
          "workflow_dispatch": {
            "inputs": {
              "upload_artifacts": {
                "description": "Upload artifacts",
                "required": false,
                "default": "true"
              }
            }
          }
        },
        "jobs": {
          "firewall-intelligence": {
            "name": "Firewall Intelligence Scan",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.10"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install requests\n"
              },
              {
                "name": "Fetch Firewall Incidents",
                "run": "echo \"\ud83d\udd0d Fetching firewall incidents from external sources...\"\npython3 bridge_backend/tools/firewall_intel/fetch_firewall_incidents.py\n"
              },
              {
                "name": "Analyze Firewall Findings",
                "run": "echo \"\ud83e\udde0 Analyzing firewall findings...\"\npython3 bridge_backend/tools/firewall_intel/analyze_firewall_findings.py\n"
              },
              {
                "name": "Display Report Summary",
                "run": "echo \"\ud83d\udcca Firewall Intelligence Report\"\necho \"================================\"\nif [ -f bridge_backend/diagnostics/firewall_report.json ]; then\n  cat bridge_backend/diagnostics/firewall_report.json\nelse\n  echo \"\u26a0\ufe0f  Report not generated\"\nfi\n"
              },
              {
                "name": "Upload Firewall Report Artifact",
                "if": "${{ github.event.inputs.upload_artifacts != 'false' }}",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "firewall-report",
                  "path": "bridge_backend/diagnostics/firewall_report.json",
                  "retention-days": 30
                }
              },
              {
                "name": "Upload Generated Allowlist",
                "if": "${{ github.event.inputs.upload_artifacts != 'false' }}",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "generated-allowlist",
                  "path": "network_policies/generated_allowlist.yaml",
                  "retention-days": 30
                }
              },
              {
                "name": "Firewall Intelligence Complete",
                "run": "echo \"\u2705 Firewall intelligence scan complete\"\necho \"\ud83d\udcc4 Artifacts uploaded for review\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "env-sync.yml",
      "name": "\ud83d\udd01 Bridge Env Sync",
      "config": {
        "name": "\ud83d\udd01 Bridge Env Sync",
        "true": {
          "workflow_dispatch": null,
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "sync": {
            "name": "Environment Synchronization Pipeline",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "\ud83e\uddf0 Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "\ud83d\udc0d Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "\ud83d\udce6 Install Dependencies",
                "run": "pip install httpx python-dotenv pynacl\n"
              },
              {
                "name": "\ud83d\udd04 Sync Environment Variables",
                "env": {
                  "RENDER_API_KEY": "${{ secrets.RENDER_API_KEY }}",
                  "RENDER_SERVICE_ID": "${{ secrets.RENDER_SERVICE_ID }}",
                  "GITHUB_TOKEN": "${{ secrets.GITHUB_TOKEN }}",
                  "GITHUB_REPO": "${{ github.repository }}"
                },
                "run": "echo \"\ud83d\udd04 Syncing from Render to GitHub...\"\npython3 -m bridge_backend.cli.genesisctl env sync --target github --from render || echo \"\u26a0\ufe0f Sync completed with warnings\"\n"
              },
              {
                "name": "\ud83d\udce4 Export Sync Snapshot",
                "env": {
                  "RENDER_API_KEY": "${{ secrets.RENDER_API_KEY }}",
                  "RENDER_SERVICE_ID": "${{ secrets.RENDER_SERVICE_ID }}"
                },
                "run": "echo \"\ud83d\udce4 Exporting sync snapshot...\"\npython3 -m bridge_backend.cli.genesisctl env export --target github --source render\n"
              },
              {
                "name": "\ud83d\udd0d Verify Environment Parity",
                "env": {
                  "RENDER_API_KEY": "${{ secrets.RENDER_API_KEY }}",
                  "RENDER_SERVICE_ID": "${{ secrets.RENDER_SERVICE_ID }}",
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}",
                  "GITHUB_TOKEN": "${{ secrets.GITHUB_TOKEN }}",
                  "GITHUB_REPO": "${{ github.repository }}"
                },
                "run": "echo \"\ud83d\udd0d Running post-sync verification...\"\npython3 -m bridge_backend.diagnostics.verify_env_sync || echo \"\u26a0\ufe0f Drift detected - review the parity report\"\n"
              },
              {
                "name": "\ud83d\udcca Upload Sync Report",
                "uses": "actions/upload-artifact@v4",
                "if": "always()",
                "with": {
                  "name": "env_sync_report",
                  "path": "bridge_backend/logs/env_sync_report.json\nbridge_backend/logs/env_parity_check.json\nbridge_backend/config/.env.sync.json\n",
                  "retention-days": 30
                }
              },
              {
                "name": "\ud83d\udcdd Generate Audit Documentation",
                "if": "always()",
                "run": "echo \"\ud83d\udcdd Generating audit documentation...\"\npython3 - <<'EOF'\nimport json\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\n\n# Load reports\nlogs_dir = Path(\"bridge_backend/logs\")\ndocs_dir = Path(\"docs/audit\")\ndocs_dir.mkdir(parents=True, exist_ok=True)\n\nsync_report_path = logs_dir / \"env_sync_report.json\"\nparity_report_path = logs_dir / \"env_parity_check.json\"\n\naudit_content = f\"\"\"# GitHub Environment Sync Log\n\n**Sync Date:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\n**Workflow:** {os.getenv('GITHUB_WORKFLOW', 'env-sync')}\n**Run ID:** {os.getenv('GITHUB_RUN_ID', 'N/A')}\n**Run Number:** {os.getenv('GITHUB_RUN_NUMBER', 'N/A')}\n\n## Sync Report\n\n\"\"\"\n\nif sync_report_path.exists():\n    with open(sync_report_path) as f:\n        sync_data = json.load(f)\n    \n    audit_content += f\"\"\"**Source:** {sync_data.get('source', 'unknown')}\n**Target:** {sync_data.get('provider', 'unknown')}\n**Timestamp:** {sync_data.get('synced_at', 'N/A')}\n**Variables Exported:** {len(sync_data.get('variables', {}))}\n\n\"\"\"\n\nif parity_report_path.exists():\n    with open(parity_report_path) as f:\n        parity_data = json.load(f)\n    \n    has_drift = parity_data.get('has_drift', True)\n    status = \"\u274c Drift Detected\" if has_drift else \"\u2705 No Drift\"\n    \n    audit_content += f\"\"\"## Parity Verification\n\n**Status:** {status}\n**Verified At:** {parity_data.get('verified_at', 'N/A')}\n\n### Summary\n\n- Missing in Render: {len(parity_data.get('missing_in_render', []))}\n- Missing in Netlify: {len(parity_data.get('missing_in_netlify', []))}\n- Missing in GitHub: {len(parity_data.get('missing_in_github', []))}\n- Conflicts: {len(parity_data.get('conflicts', {}))}\n\n\"\"\"\n    \n    if parity_data.get('missing_in_github'):\n        audit_content += \"\\n### Variables Missing in GitHub\\n\\n\"\n        for var in parity_data['missing_in_github'][:20]:\n            audit_content += f\"- {var}\\n\"\n        if len(parity_data['missing_in_github']) > 20:\n            audit_content += f\"\\n... and {len(parity_data['missing_in_github']) - 20} more\\n\"\n\naudit_content += f\"\"\"\n---\n\n**Genesis Event ID:** envsync.commit:{os.getenv('GITHUB_SHA', 'unknown')[:7]}\n\"\"\"\n\n# Save audit document\naudit_path = docs_dir / \"GITHUB_ENV_AUDIT.md\"\nwith open(audit_path, 'w') as f:\n    f.write(audit_content)\n\nprint(f\"\u2705 Audit documentation saved to {audit_path}\")\nEOF\n"
              },
              {
                "name": "\ud83d\udce4 Upload Audit Documentation",
                "uses": "actions/upload-artifact@v4",
                "if": "always()",
                "with": {
                  "name": "env_sync_audit",
                  "path": "docs/audit/GITHUB_ENV_AUDIT.md",
                  "retention-days": 90
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "quantum_dominion.yml",
      "name": "Quantum Dominion Security",
      "config": {
        "name": "Quantum Dominion Security",
        "true": {
          "push": {
            "branches": [
              "main",
              "develop"
            ]
          },
          "pull_request": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "permissions": {
          "contents": "read",
          "security-events": "write"
        },
        "jobs": {
          "quantum-security": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12",
                  "cache": "pip",
                  "cache-dependency-path": "bridge_backend/requirements.txt"
                }
              },
              {
                "name": "Cache pip packages",
                "uses": "actions/cache@v4",
                "with": {
                  "path": "~/.cache/pip",
                  "key": "${{ runner.os }}-pip-quantum-${{ hashFiles('bridge_backend/requirements.txt') }}",
                  "restore-keys": "${{ runner.os }}-pip-quantum-\n${{ runner.os }}-pip-\n"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install -r bridge_backend/requirements.txt\n"
              },
              {
                "name": "Set environment variables",
                "run": "echo \"FORGE_DOMINION_MODE=${{ vars.FORGE_DOMINION_MODE || 'sovereign' }}\" >> $GITHUB_ENV\necho \"FORGE_DOMINION_VERSION=${{ vars.FORGE_DOMINION_VERSION || '1.9.7s' }}\" >> $GITHUB_ENV\necho \"ENVIRONMENT=${{ github.ref == 'refs/heads/main' && 'production' || 'staging' }}\" >> $GITHUB_ENV\nif [ -n \"${{ secrets.FORGE_DOMINION_ROOT }}\" ]; then\n  echo \"FORGE_DOMINION_ROOT=${{ secrets.FORGE_DOMINION_ROOT }}\" >> $GITHUB_ENV\nfi\n"
              },
              {
                "name": "Run Quantum Predeploy Orchestrator",
                "id": "quantum_check",
                "run": "python3 bridge_backend/runtime/quantum_predeploy_orchestrator.py\n",
                "continue-on-error": true
              },
              {
                "name": "Upload Security Reports",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "quantum-security-reports-${{ github.run_number }}",
                  "path": ".alik/predeploy_report.json\n.alik/forge_state.json\n",
                  "retention-days": 7
                }
              },
              {
                "name": "Extract Security Metrics",
                "if": "always()",
                "run": "if [ -f .alik/predeploy_report.json ]; then\n  echo \"### \ud83d\udf02 Quantum Dominion Security Report\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  python3 .github/scripts/extract_security_metrics.py\nfi\n"
              },
              {
                "name": "Check Critical Failures",
                "if": "always()",
                "run": "if [ -f .alik/predeploy_report.json ]; then\n  python3 .github/scripts/check_critical_failures.py\nfi\n"
              },
              {
                "name": "Report Status",
                "if": "always()",
                "run": "if [ \"${{ steps.quantum_check.outcome }}\" == \"success\" ]; then\n  echo \"\u2705 Quantum Dominion security checks PASSED\"\nelse\n  echo \"\u274c Quantum Dominion security checks FAILED\"\n  exit 1\nfi\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "hooks-triage.yml",
      "name": "Hooks Triage",
      "config": {
        "name": "Hooks Triage",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "15 * * * *"
            }
          ]
        },
        "jobs": {
          "hooks-triage": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install requests\n"
              },
              {
                "name": "Run Hooks Triage",
                "env": {
                  "BRIDGE_BASE_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}",
                  "BRIDGE_CONTROL_SECRET": "${{ secrets.BRIDGE_CONTROL_SECRET }}"
                },
                "run": "cd bridge_backend\npython3 scripts/hooks_triage.py --manual\n"
              },
              {
                "name": "Upload Diagnostics to Bridge",
                "if": "always()",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "if [ -f bridge_backend/hooks_triage_report.json ]; then\n  curl -X POST \"${{ secrets.BRIDGE_URL }}/api/diagnostics\" \\\n    -H \"Content-Type: application/json\" \\\n    -d @bridge_backend/hooks_triage_report.json || true\nfi\n"
              },
              {
                "name": "Upload Report Artifact",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "hooks-triage-report",
                  "path": "bridge_backend/hooks_triage_report.json",
                  "if-no-files-found": "ignore"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "environment_parity_guard.yml",
      "name": "Environment Parity Guard",
      "config": {
        "name": "Environment Parity Guard",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "0 2 * * *"
            }
          ]
        },
        "jobs": {
          "env-parity": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "run": "python3 .github/scripts/env_parity_guard.py"
              },
              {
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "env_parity_guard",
                  "path": "bridge_backend/diagnostics/env_parity_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "triage_federation.yml",
      "name": "Triage Federation Heartbeat",
      "config": {
        "name": "Triage Federation Heartbeat",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": null,
          "schedule": [
            {
              "cron": "*/30 * * * *"
            }
          ],
          "workflow_dispatch": null
        },
        "jobs": {
          "triage": {
            "runs-on": "ubuntu-latest",
            "timeout-minutes": 15,
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -q httpx python-dateutil || true\n"
              },
              {
                "name": "Prepare paths",
                "run": "echo \"DIAG=bridge_backend/diagnostics\" >> $GITHUB_ENV\nmkdir -p bridge_backend/tools/triage/common\nmkdir -p bridge_backend/diagnostics\n"
              },
              {
                "name": "API Triage (auto-heal)",
                "env": {
                  "PUBLIC_API_BASE": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "TRIAGE_MAX_RETRIES": 4,
                  "TRIAGE_TIMEOUT_MS": 8000,
                  "TRIAGE_BACKOFF_BASE": 0.8,
                  "TRIAGE_BACKOFF_FACTOR": 2.0,
                  "TRIAGE_JITTER_MAX": 0.35,
                  "TRIAGE_CIRCUIT_BREAKER_FAILS": 6
                },
                "run": "python3 bridge_backend/tools/triage/api_triage.py || true\n"
              },
              {
                "name": "Generate Parity Report (for endpoint triage)",
                "run": "python3 bridge_backend/tools/parity_engine.py || true\n"
              },
              {
                "name": "Endpoint Triage (parity-aware)",
                "env": {
                  "PUBLIC_API_BASE": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "ENDPOINT_TRIAGE_LIMIT": 20,
                  "TRIAGE_MAX_RETRIES": 4,
                  "TRIAGE_TIMEOUT_MS": 8000,
                  "TRIAGE_BACKOFF_BASE": 0.8,
                  "TRIAGE_BACKOFF_FACTOR": 2.0,
                  "TRIAGE_JITTER_MAX": 0.35,
                  "TRIAGE_CIRCUIT_BREAKER_FAILS": 6
                },
                "run": "python3 bridge_backend/tools/triage/endpoint_triage.py || true\n"
              },
              {
                "name": "Diagnostics Federation (heartbeat & guard)",
                "env": {
                  "FEDERATION_MAX_WAIT_S": 120
                },
                "run": "python3 bridge_backend/tools/triage/diagnostics_federate.py || true\n"
              },
              {
                "name": "Upload Triage Artifacts",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "triage-federation-reports",
                  "path": "${{ env.DIAG }}/*.json"
                }
              },
              {
                "name": "Determine Outcome",
                "id": "gate",
                "run": "python - <<'PY'\nimport json, pathlib\np = pathlib.Path(\"bridge_backend/diagnostics/triage_federation_report.json\")\nok = False\nif p.exists():\n  ok = json.loads(p.read_text()).get(\"ok\", False)\nprint(f\"::set-output name=ok::{str(ok).lower()}\")\nPY\n"
              },
              {
                "name": "Fail if federation failed after auto-heal",
                "if": "steps.gate.outputs.ok == 'false' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')",
                "run": "echo \"\u274c Federation triage failed after retries. See artifacts.\"\nexit 1\n"
              },
              {
                "name": "Warn if federation degraded on PR",
                "if": "steps.gate.outputs.ok == 'false' && github.event_name == 'pull_request'",
                "run": "echo \"\u26a0\ufe0f  Federation triage degraded (non-critical for PR context)\"\necho \"This is expected for PRs where backend services may not be fully deployed.\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "reflex_loop.yml",
      "name": "EAN Reflex Loop",
      "config": {
        "name": "EAN Reflex Loop",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "0 */12 * * *"
            }
          ],
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "reflex": {
            "runs-on": "ubuntu-latest",
            "permissions": {
              "contents": "read",
              "pull-requests": "write"
            },
            "steps": [
              {
                "name": "Checkout repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Run Reflex Loop",
                "run": "python3 .github/autonomy_node/reflex.py",
                "env": {
                  "GITHUB_TOKEN": "${{ secrets.GITHUB_TOKEN }}",
                  "GITHUB_REPOSITORY": "${{ github.repository }}"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "firewall_autonomy_engine.yml",
      "name": "Firewall Intelligence and Autonomy Engine",
      "config": {
        "name": "Firewall Intelligence and Autonomy Engine",
        "true": {
          "schedule": [
            {
              "cron": "0 3 * * *"
            }
          ],
          "workflow_dispatch": {
            "inputs": {
              "force_run": {
                "description": "Force run even if no issues detected",
                "required": false,
                "default": "false"
              }
            }
          }
        },
        "jobs": {
          "firewall-autonomy": {
            "name": "Firewall Intelligence + Autonomy",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.10"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install requests\n"
              },
              {
                "name": "Create Necessary Directories",
                "run": "mkdir -p bridge_backend/diagnostics\nmkdir -p vault/autonomy\nmkdir -p network_policies\n"
              },
              {
                "name": "Run Firewall Intelligence and Autonomy Engine",
                "run": "echo \"\ud83e\udd16 Starting Firewall Intelligence and Autonomy Engine...\"\npython3 bridge_backend/tools/firewall_intel/firewall_autonomy_engine.py\n"
              },
              {
                "name": "Display Autonomy Log",
                "run": "echo \"\ud83d\udcca Autonomy Engine Execution Log\"\necho \"=================================\"\nif [ -f bridge_backend/diagnostics/firewall_autonomy_log.json ]; then\n  cat bridge_backend/diagnostics/firewall_autonomy_log.json\nelse\n  echo \"\u26a0\ufe0f  No autonomy log generated\"\nfi\n"
              },
              {
                "name": "Check for High Severity Issues",
                "id": "check_severity",
                "run": "if [ -f bridge_backend/diagnostics/firewall_report.json ]; then\n  SEVERITY=$(python3 -c \"import json; print(json.load(open('bridge_backend/diagnostics/firewall_report.json'))['summary']['severity'])\")\n  echo \"severity=$SEVERITY\" >> $GITHUB_OUTPUT\n  echo \"\ud83d\udd0d Detected severity: $SEVERITY\"\nelse\n  echo \"severity=unknown\" >> $GITHUB_OUTPUT\nfi\n"
              },
              {
                "name": "Upload Firewall Report",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "firewall-autonomy-report",
                  "path": "bridge_backend/diagnostics/firewall_report.json\nbridge_backend/diagnostics/firewall_autonomy_log.json\nbridge_backend/diagnostics/firewall_incidents.json\n",
                  "retention-days": 90
                }
              },
              {
                "name": "Upload Generated Policies",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "generated-network-policies",
                  "path": "network_policies/generated_allowlist.yaml",
                  "retention-days": 90
                }
              },
              {
                "name": "Upload Autonomy Vault Records",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "autonomy-vault-records",
                  "path": "vault/autonomy/firewall_*",
                  "retention-days": 90
                }
              },
              {
                "name": "Alert on High Severity",
                "if": "steps.check_severity.outputs.severity == 'high'",
                "run": "echo \"\ud83d\udea8 HIGH SEVERITY FIREWALL ISSUES DETECTED\"\necho \"==========================================\"\necho \"The Autonomy Engine has detected high-severity firewall issues.\"\necho \"Human review and approval is required before applying policies.\"\necho \"\"\necho \"\ud83d\udcc4 Review artifacts:\"\necho \"  - firewall-autonomy-report\"\necho \"  - generated-network-policies\"\necho \"  - autonomy-vault-records\"\necho \"\"\necho \"\ud83d\udee1\ufe0f Next steps:\"\necho \"  1. Review the firewall_report.json for issue details\"\necho \"  2. Review the generated_allowlist.yaml for policy recommendations\"\necho \"  3. Approve and apply policies if appropriate\"\n"
              },
              {
                "name": "Complete",
                "run": "echo \"\u2705 Firewall Intelligence and Autonomy Engine execution complete\"\necho \"\ud83d\udcca Check artifacts for detailed reports and logs\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "self-test.yml",
      "name": "Self-Test SR-AIbridge",
      "config": {
        "name": "Self-Test SR-AIbridge",
        "on": {
          "workflow_run": {
            "workflows": [
              "Deploy SR-AIbridge"
            ],
            "types": [
              "completed"
            ]
          },
          "workflow_dispatch": {
            "inputs": {
              "backend_url": {
                "description": "Backend URL to test against",
                "required": false,
                "default": "https://bridge.sr-aibridge.com",
                "type": "string"
              },
              "test_timeout": {
                "description": "Test timeout in minutes",
                "required": false,
                "default": "10",
                "type": "string"
              }
            }
          },
          "schedule": [
            {
              "cron": "0 */4 * * *"
            }
          ]
        },
        "jobs": {
          "wait-for-deployment": {
            "name": "Wait for Deployment Ready",
            "runs-on": "ubuntu-latest",
            "if": "github.event.workflow_run.conclusion == 'success' || github.event_name != 'workflow_run'",
            "outputs": {
              "backend_url": "${{ steps.determine-url.outputs.backend_url }}"
            },
            "steps": [
              {
                "name": "Determine backend URL",
                "id": "determine-url",
                "run": "if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n  echo \"backend_url=${{ github.event.inputs.backend_url }}\" >> $GITHUB_OUTPUT\nelse\n  echo \"backend_url=${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}\" >> $GITHUB_OUTPUT\nfi\n"
              },
              {
                "name": "Wait for backend to be responsive",
                "run": "BACKEND_URL=\"${{ steps.determine-url.outputs.backend_url }}\"\necho \"Waiting for backend at: $BACKEND_URL\"\n\n# Wait up to 5 minutes for the backend to respond\nfor i in {1..30}; do\n  if curl -f -s \"$BACKEND_URL/health\" > /dev/null; then\n    echo \"\u2705 Backend is responsive\"\n    exit 0\n  fi\n  echo \"\u23f3 Attempt $i/30: Backend not ready, waiting 10s...\"\n  sleep 10\ndone\n\necho \"\u274c Backend failed to respond after 5 minutes\"\nexit 1\n"
              }
            ]
          },
          "backend-health-tests": {
            "name": "Backend Health Tests",
            "runs-on": "ubuntu-latest",
            "needs": "wait-for-deployment",
            "timeout-minutes": "${{ fromJSON(github.event.inputs.test_timeout || '10') }}",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "cd bridge_backend\npip install -r requirements.txt\n"
              },
              {
                "name": "Run comprehensive self-test",
                "id": "self-test",
                "run": "cd bridge_backend\nBACKEND_URL=\"${{ needs.wait-for-deployment.outputs.backend_url }}\"\necho \"Running self-test against: $BACKEND_URL\"\n\n# Run self-test with JSON output for better parsing\npython3 self_test.py --url \"$BACKEND_URL\" --json > self_test_results.json\n\n# Check if self-test passed\nif [ $? -eq 0 ]; then\n  echo \"\u2705 Self-test completed successfully\"\n  echo \"test_status=success\" >> $GITHUB_OUTPUT\nelse\n  echo \"\u274c Self-test failed\"\n  echo \"test_status=failure\" >> $GITHUB_OUTPUT\nfi\n\n# Display results\ncat self_test_results.json\n"
              },
              {
                "name": "Upload test results",
                "uses": "actions/upload-artifact@v4",
                "if": "always()",
                "with": {
                  "name": "self-test-results",
                  "path": "bridge_backend/self_test_results.json",
                  "retention-days": 30
                }
              },
              {
                "name": "Parse and display test summary",
                "if": "always()",
                "run": "cd bridge_backend\nif [ -f self_test_results.json ]; then\n  echo \"## \ud83e\uddea Self-Test Results\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n\n  # Extract summary using Python\n  python3 -c \"\nimport json\ntry:\n    with open('self_test_results.json', 'r') as f:\n        results = json.load(f)\n\n    summary = results.get('summary', {})\n    total = summary.get('total', 0)\n    passed = summary.get('passed', 0)\n    failed = summary.get('failed', 0)\n    errors = summary.get('errors', 0)\n\n    success_rate = (passed / total * 100) if total > 0 else 0\n\n    print(f'**Total Tests:** {total}')\n    print(f'**\u2705 Passed:** {passed}')\n    print(f'**\u274c Failed:** {failed}')\n    print(f'**\ud83d\udea8 Errors:** {errors}')\n    print(f'**\ud83d\udcc8 Success Rate:** {success_rate:.1f}%')\n    print()\n\n    if failed > 0 or errors > 0:\n        print('### Failed Tests:')\n        for test in results.get('tests', []):\n            if not test.get('passed', True):\n                name = test.get('name', 'Unknown')\n                error = test.get('error', 'No error details')\n                print(f'- **{name}**: {error}')\nexcept Exception as e:\n    print(f'Could not parse results: {e}')\n  \" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"\u274c No test results file found\" >> $GITHUB_STEP_SUMMARY\nfi\n"
              }
            ]
          },
          "frontend-connectivity-test": {
            "name": "Frontend Connectivity Test",
            "runs-on": "ubuntu-latest",
            "needs": "wait-for-deployment",
            "steps": [
              {
                "name": "Test frontend accessibility",
                "run": "FRONTEND_URL=\"${{ secrets.FRONTEND_URL || 'https://sr-aibridge.netlify.app' }}\"\necho \"Testing frontend at: $FRONTEND_URL\"\n\n# Test frontend loads\nif curl -f -s \"$FRONTEND_URL\" > /dev/null; then\n  echo \"\u2705 Frontend is accessible\"\nelse\n  echo \"\u274c Frontend is not accessible\"\n  exit 1\nfi\n"
              },
              {
                "name": "Test API configuration",
                "run": "FRONTEND_URL=\"${{ secrets.FRONTEND_URL || 'https://sr-aibridge.netlify.app' }}\"\nBACKEND_URL=\"${{ needs.wait-for-deployment.outputs.backend_url }}\"\n\necho \"Verifying frontend can reach backend...\"\necho \"Frontend: $FRONTEND_URL\"\necho \"Backend: $BACKEND_URL\"\n\n# This is a basic connectivity test\n# In a real scenario, you might want to use a headless browser\n# to test the actual frontend-backend communication\n\nif curl -f -s \"$BACKEND_URL/health\" > /dev/null; then\n  echo \"\u2705 Backend is reachable from CI\"\nelse\n  echo \"\u26a0\ufe0f Backend not reachable from CI (may still work from frontend)\"\nfi\n"
              }
            ]
          },
          "notify-results": {
            "name": "Notify Test Results",
            "runs-on": "ubuntu-latest",
            "needs": [
              "backend-health-tests",
              "frontend-connectivity-test"
            ],
            "if": "always()",
            "steps": [
              {
                "name": "Determine overall status",
                "id": "status",
                "run": "if [ \"${{ needs.backend-health-tests.result }}\" = \"success\" ] && \\\n   [ \"${{ needs.frontend-connectivity-test.result }}\" = \"success\" ]; then\n  echo \"status=success\" >> $GITHUB_OUTPUT\n  echo \"message=All self-tests passed \u2705\" >> $GITHUB_OUTPUT\nelse\n  echo \"status=failure\" >> $GITHUB_OUTPUT\n  echo \"message=Some self-tests failed \u274c\" >> $GITHUB_OUTPUT\nfi\n"
              },
              {
                "name": "Create status summary",
                "run": "echo \"## \ud83d\ude80 SR-AIbridge Self-Test Summary\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Overall Status:** ${{ steps.status.outputs.message }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"### Test Results:\" >> $GITHUB_STEP_SUMMARY\necho \"- **Backend Health Tests:** ${{ needs.backend-health-tests.result }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Frontend Connectivity:** ${{ needs.frontend-connectivity-test.result }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Tested at:** $(date -u)\" >> $GITHUB_STEP_SUMMARY"
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_autonomy.yml",
      "name": "Bridge Autonomy Healer",
      "config": {
        "name": "Bridge Autonomy Healer",
        "true": {
          "workflow_run": {
            "workflows": [
              "Build & Deploy"
            ],
            "types": [
              "completed"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "heal": {
            "runs-on": "ubuntu-latest",
            "if": "${{ failure() || github.event.workflow_run.conclusion == 'failure' }}",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Trigger Bridge Autonomy",
                "run": "if [ -n \"${{ vars.PUBLIC_API_BASE }}\" ] && [ -n \"${{ secrets.AUTONOMY_API_TOKEN }}\" ]; then\n  curl -X POST \"${{ vars.PUBLIC_API_BASE }}/api/autonomy/incident\" \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer ${{ secrets.AUTONOMY_API_TOKEN }}\" \\\n    -d '{\n      \"kind\": \"deploy.failure\",\n      \"source\": \"github\",\n      \"details\": {\n        \"workflow\": \"build-deploy\",\n        \"run_id\": \"${{ github.run_id }}\",\n        \"repository\": \"${{ github.repository }}\"\n      }\n    }'\nelse\n  echo \"\u26a0\ufe0f Autonomy not configured - missing PUBLIC_API_BASE or AUTONOMY_API_TOKEN\"\nfi\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "build_preflight.yml",
      "name": "Build Preflight (Triage)",
      "config": {
        "name": "Build Preflight (Triage)",
        "true": {
          "pull_request": null,
          "push": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "triage": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Use Node 20",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": 20,
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Run Build Triage",
                "working-directory": "bridge-frontend",
                "run": "python3 scripts/build_triage.py\n"
              },
              {
                "name": "Upload Triage Report",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "build_triage_report",
                  "path": "bridge_backend/diagnostics/build_triage_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge-deploy.yml",
      "name": "\ud83c\udf09 Bridge Deploy (DISABLED - Use deploy.yml)",
      "config": {
        "name": "\ud83c\udf09 Bridge Deploy (DISABLED - Use deploy.yml)",
        "true": {
          "workflow_dispatch": null
        },
        "permissions": {
          "contents": "read"
        },
        "jobs": {
          "build-and-deploy": {
            "runs-on": "ubuntu-latest",
            "env": {
              "FORGE_DOMINION_ROOT": "${{ secrets.FORGE_DOMINION_ROOT }}",
              "DOMINION_SEAL": "${{ secrets.DOMINION_SEAL }}",
              "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
              "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
            },
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": 20
                }
              },
              {
                "name": "Install Frontend Dependencies",
                "run": "cd bridge-frontend\nnpm ci\n"
              },
              {
                "name": "Build Bridge Frontend",
                "run": "cd bridge-frontend\nnpm run build\n"
              },
              {
                "name": "Export Forge Runtime",
                "run": "python3 bridge_backend/forge/export_runtime.py\n"
              },
              {
                "name": "Deploy to Netlify",
                "uses": "nwtgck/actions-netlify@v3.0",
                "with": {
                  "publish-dir": "bridge-frontend/dist",
                  "production-deploy": true,
                  "github-token": "${{ secrets.GITHUB_TOKEN }}",
                  "deploy-message": "\ud83d\udef0\ufe0f Sovereign Bridge: Automatic Deploy from Forge Dominion",
                  "enable-pull-request-comment": false,
                  "enable-commit-comment": false
                },
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
                }
              },
              {
                "name": "Notify Forge Dominion",
                "run": "curl -X POST \"https://sovereign.bridge/api/forge/deploy\" \\\n-H \"Authorization: Bearer $DOMINION_SEAL\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"status\": \"deployed\", \"env\": \"${{ github.ref_name }}\", \"build_id\": \"${{ github.run_id }}\"}' \\\n|| echo \"Warning: Failed to notify Forge Dominion endpoint\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "envsync-manifest-validation.yml",
      "name": "EnvSync Manifest Validation",
      "config": {
        "name": "EnvSync Manifest Validation",
        "true": {
          "pull_request": {
            "paths": [
              "bridge_backend/.genesis/envsync_seed_manifest.env",
              "scripts/validate_envsync_manifest.py"
            ]
          },
          "push": {
            "branches": [
              "main"
            ],
            "paths": [
              "bridge_backend/.genesis/envsync_seed_manifest.env"
            ]
          }
        },
        "jobs": {
          "validate-manifest": {
            "name": "Validate EnvSync Seed Manifest",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Validate EnvSync Seed Manifest",
                "run": "echo \"\ud83d\udd0d Validating EnvSync Seed Manifest...\"\npython3 scripts/validate_envsync_manifest.py\n"
              },
              {
                "name": "Check variable count",
                "run": "echo \"\ud83d\udcca Analyzing manifest contents...\"\nvar_count=$(grep -E '^[A-Z_]+=.+' bridge_backend/.genesis/envsync_seed_manifest.env | wc -l)\necho \"\u2705 Found $var_count variables in manifest\"\n\n# Ensure we have at least the core variables\nif [ \"$var_count\" -lt 20 ]; then\n  echo \"\u274c ERROR: Expected at least 20 variables, found $var_count\"\n  exit 1\nfi\n"
              },
              {
                "name": "Check for secrets in manifest",
                "run": "echo \"\ud83d\udee1\ufe0f Checking for potential secrets...\"\n\n# List of patterns that should NOT appear as values in the manifest\n# (they can appear in variable names, but values should be safe)\nsuspicious_patterns=(\n  'BEGIN.*PRIVATE KEY'\n  'Bearer [A-Za-z0-9]'\n  'password.*:'\n  'api_key.*:.*[A-Za-z0-9]{32}'\n)\n\nfound_suspicious=false\n\nfor pattern in \"${suspicious_patterns[@]}\"; do\n  if grep -E \"$pattern\" bridge_backend/.genesis/envsync_seed_manifest.env; then\n    echo \"\u26a0\ufe0f  WARNING: Potentially sensitive pattern found: $pattern\"\n    found_suspicious=true\n  fi\ndone\n\nif [ \"$found_suspicious\" = true ]; then\n  echo \"\"\n  echo \"\u274c ERROR: Manifest appears to contain secrets or sensitive data\"\n  echo \"Please ensure the manifest only contains non-sensitive configuration\"\n  exit 1\nelse\n  echo \"\u2705 No obvious secrets detected\"\nfi\n"
              },
              {
                "name": "Verify metadata headers",
                "run": "echo \"\ud83d\udccb Verifying metadata headers...\"\n\nrequired_headers=(\n  \"Version:\"\n  \"Purpose:\"\n  \"AutoPropagate:\"\n  \"SyncTarget:\"\n)\n\nmissing_headers=()\n\nfor header in \"${required_headers[@]}\"; do\n  if ! grep -q \"# $header\" bridge_backend/.genesis/envsync_seed_manifest.env; then\n    missing_headers+=(\"$header\")\n  fi\ndone\n\nif [ ${#missing_headers[@]} -gt 0 ]; then\n  echo \"\u274c ERROR: Missing required metadata headers:\"\n  printf '  - %s\\n' \"${missing_headers[@]}\"\n  exit 1\nelse\n  echo \"\u2705 All required metadata headers present\"\nfi\n"
              },
              {
                "name": "Summary",
                "if": "success()",
                "run": "echo \"\"\necho \"\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\"\necho \"\u2705 EnvSync Seed Manifest validation passed!\"\necho \"\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\"\necho \"\"\necho \"Manifest: bridge_backend/.genesis/envsync_seed_manifest.env\"\necho \"Version: Genesis v2.0.1a\"\necho \"\"\necho \"The manifest is ready for deployment. Changes will be\"\necho \"automatically synchronized to Render and Netlify when\"\necho \"ENVSYNC_CANONICAL_SOURCE=file is set.\"\necho \"\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "sovereign-diagnostic-sweep.yml",
      "name": "Sovereign Diagnostic Sweep",
      "config": {
        "name": "Sovereign Diagnostic Sweep",
        "true": {
          "workflow_dispatch": {
            "inputs": {
              "scan_depth": {
                "description": "Scan depth (all_failures, recent_only)",
                "required": false,
                "type": "choice",
                "options": [
                  "all_failures",
                  "recent_only"
                ],
                "default": "recent_only"
              },
              "auto_fix": {
                "description": "Enable auto-fix for common patterns",
                "required": false,
                "type": "boolean",
                "default": false
              }
            }
          },
          "schedule": [
            {
              "cron": "0 */6 * * *"
            }
          ]
        },
        "permissions": {
          "contents": "write",
          "actions": "read",
          "checks": "read",
          "pull-requests": "write"
        },
        "jobs": {
          "failure-hunter": {
            "name": "Hunt Workflow Failures",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4",
                "with": {
                  "fetch-depth": 0
                }
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt\npip install PyYAML tabulate\n"
              },
              {
                "name": "Scan Workflow Definitions",
                "id": "scan-workflows",
                "run": "echo \"\ud83d\udd0d Scanning workflow definitions for common issues...\"\npython3 - <<'PYTHON'\nimport yaml\nimport json\nimport os\nfrom pathlib import Path\nfrom collections import defaultdict\n\nworkflows_dir = Path(\".github/workflows\")\nissues = defaultdict(list)\n\nprint(\"\ud83d\udcca Analyzing workflow files...\")\n\nfor workflow_file in workflows_dir.glob(\"*.yml\"):\n    try:\n        with open(workflow_file) as f:\n            workflow = yaml.safe_load(f)\n        \n        # Check for deprecated actions\n        workflow_str = workflow_file.read_text()\n        if \"actions/upload-artifact@v3\" in workflow_str:\n            issues[\"deprecated_actions\"].append({\n                \"file\": str(workflow_file.relative_to(\".\")),\n                \"issue\": \"Uses deprecated upload-artifact@v3\",\n                \"severity\": \"low\",\n                \"fix\": \"Update to @v4\"\n            })\n        \n        if \"actions/download-artifact@v3\" in workflow_str:\n            issues[\"deprecated_actions\"].append({\n                \"file\": str(workflow_file.relative_to(\".\")),\n                \"issue\": \"Uses deprecated download-artifact@v3\",\n                \"severity\": \"low\",\n                \"fix\": \"Update to @v4\"\n            })\n        \n        # Check for browser download issues\n        if \"playwright install\" in workflow_str or \"puppeteer\" in workflow_str:\n            if \"PUPPETEER_SKIP\" not in workflow_str and \"PLAYWRIGHT_SKIP\" not in workflow_str:\n                issues[\"browser_config\"].append({\n                    \"file\": str(workflow_file.relative_to(\".\")),\n                    \"issue\": \"Browser tools without skip flags\",\n                    \"severity\": \"medium\",\n                    \"fix\": \"Add PUPPETEER_SKIP_CHROMIUM_DOWNLOAD env var\"\n                })\n        \n        # Check for missing timeout settings\n        if workflow and \"jobs\" in workflow:\n            for job_name, job_data in workflow.get(\"jobs\", {}).items():\n                if isinstance(job_data, dict):\n                    steps = job_data.get(\"steps\", [])\n                    for step in steps:\n                        if isinstance(step, dict):\n                            # Check for long-running commands without timeout\n                            if \"run\" in step and any(cmd in str(step.get(\"run\", \"\")) for cmd in [\"npm run build\", \"npm test\", \"pytest\"]):\n                                if \"timeout-minutes\" not in step:\n                                    issues[\"missing_timeouts\"].append({\n                                        \"file\": str(workflow_file.relative_to(\".\")),\n                                        \"job\": job_name,\n                                        \"issue\": \"Long-running command without timeout\",\n                                        \"severity\": \"low\",\n                                        \"fix\": \"Add timeout-minutes to step\"\n                                    })\n                                    break  # Only report once per job\n    \n    except Exception as e:\n        print(f\"\u26a0\ufe0f Error analyzing {workflow_file.name}: {e}\")\n\n# Save results\nresults = {\n    \"total_workflows\": len(list(workflows_dir.glob(\"*.yml\"))),\n    \"issues_by_type\": {k: len(v) for k, v in issues.items()},\n    \"issues\": dict(issues)\n}\n\noutput_dir = Path(\"bridge_backend/diagnostics\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\nwith open(output_dir / \"workflow_scan_results.json\", \"w\") as f:\n    json.dump(results, indent=2, fp=f)\n\nprint(f\"\\n\ud83d\udcca Scan Results:\")\nprint(f\"  Total workflows: {results['total_workflows']}\")\nfor issue_type, count in results['issues_by_type'].items():\n    print(f\"  {issue_type}: {count} issues\")\n\n# Output for GitHub Actions\ntotal_issues = sum(results['issues_by_type'].values())\nprint(f\"\\ntotal_issues={total_issues}\")\nwith open(os.environ['GITHUB_OUTPUT'], 'a') as f:\n    f.write(f\"total_issues={total_issues}\\n\")\n    f.write(f\"has_issues={'true' if total_issues > 0 else 'false'}\\n\")\n\nPYTHON\n"
              },
              {
                "name": "Analyze Failure Patterns",
                "id": "analyze-patterns",
                "run": "echo \"\ud83e\udde0 Analyzing failure patterns...\"\npython3 - <<'PYTHON'\nimport json\nimport os\nfrom pathlib import Path\nfrom datetime import datetime, timezone\n\n# Load scan results\nscan_file = Path(\"bridge_backend/diagnostics/workflow_scan_results.json\")\nif scan_file.exists():\n    with open(scan_file) as f:\n        scan_results = json.load(f)\nelse:\n    scan_results = {\"issues\": {}}\n\n# Analyze patterns and generate fix recommendations\npatterns = {\n    \"browser_download_blocked\": {\n        \"detection\": [\"googlechromelabs.github.io\", \"storage.googleapis.com\"],\n        \"solution\": \"use_playwright_system_browsers\",\n        \"priority\": \"CRITICAL\",\n        \"auto_fixable\": True\n    },\n    \"deprecated_actions\": {\n        \"detection\": [\"@v3\"],\n        \"solution\": \"update_to_v4\",\n        \"priority\": \"LOW\",\n        \"auto_fixable\": True\n    },\n    \"missing_env_vars\": {\n        \"detection\": [\"FORGE_DOMINION_ROOT\", \"DOMINION_SEAL\"],\n        \"solution\": \"add_env_configuration\",\n        \"priority\": \"HIGH\",\n        \"auto_fixable\": False\n    }\n}\n\nfix_plan = {\n    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n    \"total_issues\": sum(len(issues) for issues in scan_results.get(\"issues\", {}).values()),\n    \"auto_fixable_count\": 0,\n    \"manual_fixes_required\": 0,\n    \"fixes\": []\n}\n\n# Generate fix recommendations\nfor issue_type, issues in scan_results.get(\"issues\", {}).items():\n    for issue in issues:\n        fix_item = {\n            \"file\": issue.get(\"file\"),\n            \"issue_type\": issue_type,\n            \"severity\": issue.get(\"severity\", \"unknown\"),\n            \"description\": issue.get(\"issue\"),\n            \"recommended_fix\": issue.get(\"fix\"),\n            \"auto_fixable\": issue.get(\"severity\") in [\"low\", \"medium\"]\n        }\n        \n        if fix_item[\"auto_fixable\"]:\n            fix_plan[\"auto_fixable_count\"] += 1\n        else:\n            fix_plan[\"manual_fixes_required\"] += 1\n        \n        fix_plan[\"fixes\"].append(fix_item)\n\n# Save fix plan\noutput_dir = Path(\"bridge_backend/diagnostics\")\nwith open(output_dir / \"autofix_plan.json\", \"w\") as f:\n    json.dump(fix_plan, indent=2, fp=f)\n\nprint(f\"\u2705 Fix plan generated:\")\nprint(f\"  Total issues: {fix_plan['total_issues']}\")\nprint(f\"  Auto-fixable: {fix_plan['auto_fixable_count']}\")\nprint(f\"  Manual fixes: {fix_plan['manual_fixes_required']}\")\n\nwith open(os.environ['GITHUB_OUTPUT'], 'a') as f:\n    f.write(f\"has_fixes={'true' if fix_plan['total_issues'] > 0 else 'false'}\\n\")\n    f.write(f\"auto_fixable={fix_plan['auto_fixable_count']}\\n\")\n\nPYTHON\n"
              },
              {
                "name": "Upload Diagnostic Results",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "workflow-diagnostic-results",
                  "path": "bridge_backend/diagnostics/workflow_scan_results.json\nbridge_backend/diagnostics/autofix_plan.json\n",
                  "retention-days": 30
                }
              },
              {
                "name": "Generate Summary Report",
                "if": "always()",
                "run": "echo \"\ud83d\udccb Generating diagnostic summary...\"\npython3 - <<'PYTHON'\nimport json\nfrom pathlib import Path\n\nscan_file = Path(\"bridge_backend/diagnostics/workflow_scan_results.json\")\nfix_file = Path(\"bridge_backend/diagnostics/autofix_plan.json\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"\ud83d\udd0d SOVEREIGN DIAGNOSTIC SWEEP SUMMARY\")\nprint(\"=\"*60 + \"\\n\")\n\nif scan_file.exists():\n    with open(scan_file) as f:\n        scan = json.load(f)\n    \n    print(f\"\ud83d\udcca Workflows Scanned: {scan.get('total_workflows', 0)}\")\n    print(f\"\\n\ud83d\udd27 Issues Detected by Type:\")\n    for issue_type, count in scan.get('issues_by_type', {}).items():\n        print(f\"  \u2022 {issue_type}: {count}\")\n\nif fix_file.exists():\n    with open(fix_file) as f:\n        fixes = json.load(f)\n    \n    print(f\"\\n\ud83d\udca1 Fix Recommendations:\")\n    print(f\"  \u2022 Auto-fixable: {fixes.get('auto_fixable_count', 0)}\")\n    print(f\"  \u2022 Manual intervention: {fixes.get('manual_fixes_required', 0)}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"\u2705 Diagnostic sweep complete!\")\nprint(\"=\"*60 + \"\\n\")\n\nPYTHON\n"
              },
              {
                "name": "Create Issue for Manual Fixes",
                "if": "steps.analyze-patterns.outputs.has_fixes == 'true' && steps.analyze-patterns.outputs.auto_fixable == '0'",
                "run": "echo \"\ud83d\udcdd Manual fixes required - artifact uploaded for review\"\necho \"Review the workflow-diagnostic-results artifact for details\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "autonomy_node.yml",
      "name": "Embedded Autonomy Node",
      "config": {
        "name": "Embedded Autonomy Node",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "schedule": [
            {
              "cron": "0 */6 * * *"
            }
          ],
          "workflow_dispatch": null
        },
        "jobs": {
          "autonomy-node": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "\ud83e\udde0 Run Embedded Autonomy Node",
                "run": "python3 .github/autonomy_node/core.py",
                "continue-on-error": true
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge-ci.yml",
      "name": "Bridge Integrity CI",
      "config": {
        "name": "Bridge Integrity CI",
        "true": {
          "push": {
            "branches": [
              "main",
              "develop"
            ]
          },
          "pull_request": {
            "branches": [
              "main",
              "develop"
            ]
          }
        },
        "jobs": {
          "validate": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11",
                  "cache": "pip",
                  "cache-dependency-path": "requirements.txt"
                }
              },
              {
                "name": "Cache pip packages",
                "uses": "actions/cache@v4",
                "with": {
                  "path": "~/.cache/pip",
                  "key": "${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}",
                  "restore-keys": "${{ runner.os }}-pip-\n"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt pytest\n"
              },
              {
                "name": "Run route sweep validator",
                "run": "python tools/route_sweep_check.py"
              },
              {
                "name": "Run tests",
                "env": {
                  "DATABASE_URL": "postgresql+asyncpg://user:pass@localhost/db",
                  "NETLIFY_ORIGIN": "*",
                  "NETLIFY_AUTH_TOKEN": "dummy-ci-test-token"
                },
                "run": "pytest -q"
              },
              {
                "name": "Lint check",
                "run": "pip install flake8\nflake8 bridge_backend --ignore=E501,W503 --exclude=bridge_backend/tests\n"
              },
              {
                "name": "Success confirmation",
                "if": "success()",
                "run": "echo \"\u2705 Bridge Integrity CI passed. Deployment may proceed.\""
              }
            ]
          },
          "emit-incidents-on-fail": {
            "if": "${{ failure() }}",
            "runs-on": "ubuntu-latest",
            "needs": "validate",
            "steps": [
              {
                "name": "Emit Netlify preview incident (if present)",
                "run": "curl -s -X POST \"$API_BASE/api/autonomy/incident\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $AUTONOMY_API_TOKEN\" \\\n  -d '{\"kind\":\"deploy.netlify.preview_failed\",\"source\":\"github\",\"details\":{\"run_id\":\"${{ github.run_id }}\"}}' || true\n"
              }
            ],
            "env": {
              "API_BASE": "${{ vars.PUBLIC_API_BASE || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com' }}",
              "AUTONOMY_API_TOKEN": "${{ secrets.AUTONOMY_API_TOKEN }}"
            }
          }
        }
      }
    },
    {
      "file": "scan_pr.yml",
      "name": "Compliance Scan (Licenses & Counterfeit)",
      "config": {
        "name": "Compliance Scan (Licenses & Counterfeit)",
        "true": {
          "pull_request": {
            "types": [
              "opened",
              "synchronize",
              "reopened"
            ]
          },
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "scan": {
            "runs-on": "ubuntu-latest",
            "permissions": {
              "contents": "read",
              "pull-requests": "write"
            },
            "steps": [
              {
                "uses": "actions/checkout@v4",
                "with": {
                  "fetch-depth": 0
                }
              },
              {
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install deps",
                "run": "python -m pip install -r bridge_backend/requirements.txt || true\npython -m pip install pyyaml\n"
              },
              {
                "name": "Determine changed files",
                "id": "diff",
                "run": "BEFORE=\"${{ github.event.before }}\"\nSHA=\"${{ github.sha }}\"\nif [ -z \"$BEFORE\" ]; then BEFORE=\"$(git rev-parse HEAD^ || echo '')\"; fi\nCHANGED=$(git diff --name-only \"$BEFORE\" \"$SHA\" | tr '\\n' ' ')\necho \"changed=$CHANGED\" >> $GITHUB_OUTPUT\n"
              },
              {
                "name": "Run scan",
                "id": "scan",
                "env": {
                  "SCAN_SIGNING_KEY": "${{ secrets.SCAN_SIGNING_KEY }}"
                },
                "run": "python bridge_backend/scripts/run_scan.py \\\n  --root . \\\n  --changed \"${{ steps.diff.outputs.changed }}\" \\\n  --pr \"${{ github.event.number }}\" \\\n  --commit \"${{ github.sha }}\"\n"
              },
              {
                "name": "Upload scan artifacts",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "compliance-scan-${{ github.sha }}",
                  "path": "bridge_backend/scan_reports"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "git_sovereign_operations.yml",
      "name": "\ud83c\udf0c Git Sovereign Operations",
      "config": {
        "name": "\ud83c\udf0c Git Sovereign Operations",
        "true": {
          "workflow_dispatch": {
            "inputs": {
              "operation": {
                "description": "Sovereign Operation",
                "required": true,
                "type": "choice",
                "options": [
                  "autonomous_optimization",
                  "reality_alteration",
                  "engine_resonance",
                  "system_healing",
                  "perfect_version_creation"
                ]
              },
              "target": {
                "description": "Operation Target",
                "required": false,
                "default": "full_bridge"
              },
              "authority_level": {
                "description": "Authority Level",
                "required": false,
                "type": "choice",
                "default": "cosmic_sovereignty",
                "options": [
                  "cosmic_sovereignty",
                  "admiral_trust",
                  "autonomous_approval"
                ]
              }
            }
          },
          "schedule": [
            {
              "cron": "0 0 * * *"
            }
          ],
          "push": {
            "branches": [
              "cosmic/**",
              "sovereign/**"
            ]
          }
        },
        "env": {
          "GIT_SOVEREIGN_MODE": "active",
          "AUTHORITY_LEVEL": "COSMIC_SOVEREIGNTY",
          "CONSTRAINT_LEVEL": "NONE"
        },
        "jobs": {
          "git_sovereign_commissioning": {
            "name": "\ud83c\udf96\ufe0f Git Sovereign Agent Commissioning",
            "runs-on": "ubuntu-latest",
            "permissions": {
              "contents": "write",
              "actions": "write",
              "deployments": "write"
            },
            "steps": [
              {
                "name": "\ud83c\udf0c Activate Cosmic Authority",
                "run": "echo \"\ud83d\udd13 SOVEREIGN_AGENT_ACTIVATED\"\necho \"\ud83c\udf0c BRIDGE_TECH_INTEGRATION_COMPLETE\"\necho \"\ud83c\udfaf AUTONOMOUS_OPERATIONS_ENGAGED\"\necho \"\ud83d\ude80 GIT_IS_NOW_BRIDGE_OPERATIVE\"\n"
              },
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4",
                "with": {
                  "fetch-depth": 0
                }
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install -e bridge_backend/\n"
              },
              {
                "name": "\ud83d\udf02 Initialize SDTF Integration",
                "run": "echo \"Initializing Sovereign Dominion Token Forge integration...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import SDTFGitIntegration\n\nsdtf = SDTFGitIntegration()\nstatus = sdtf.get_forge_status()\n\nprint('\ud83d\udf02 SDTF Integration Status:')\nprint(f'  Mode: {status[\\\"mode\\\"]}')\nprint(f'  Version: {status[\\\"version\\\"]}')\nprint(f'  Authority: {status[\\\"authority\\\"]}')\nprint(f'  Capabilities: {len(status[\\\"capabilities\\\"])}')\n\"\n"
              },
              {
                "name": "\ud83d\udd27 Initialize BRH Integration",
                "run": "echo \"Initializing Bridge Runtime Handler integration...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import BRHGitIntegration\n\nbrh = BRHGitIntegration()\nstatus = brh.get_brh_status()\n\nprint('\ud83d\udd27 BRH Integration Status:')\nprint(f'  Authority: {status[\\\"authority\\\"]}')\nprint(f'  Deployment Authority: {status[\\\"deployment_authority\\\"]}')\nprint(f'  Capabilities: {len(status[\\\"capabilities\\\"])}')\n\"\n"
              },
              {
                "name": "\ud83c\udf1f Initialize HXO Nexus Integration",
                "run": "echo \"Initializing HXO Nexus integration...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import HXOGitIntegration\n\nhxo = HXOGitIntegration()\nstatus = hxo.get_hxo_status()\n\nprint('\ud83c\udf1f HXO Nexus Integration Status:')\nprint(f'  Authority: {status[\\\"authority\\\"]}')\nprint(f'  Total Engines: {status[\\\"total_engines\\\"]}')\nprint(f'  Quantum Coherence: {status[\\\"quantum_coherence\\\"]}')\nprint(f'  Harmonic Field: {status[\\\"harmonic_field\\\"]}')\n\"\n"
              },
              {
                "name": "\ud83c\udfaf Validate Sovereign Manifest",
                "run": "echo \"Validating Git Sovereign Agent manifest...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import GitSovereignManifest\n\nmanifest = GitSovereignManifest()\n\nprint('\ud83c\udfaf Git Sovereign Manifest:')\nprint(f'  Version: {manifest.version}')\nprint(f'  Status: {manifest.status}')\nprint(f'  Initiative Level: {manifest.initiative_level}')\nprint(f'  Constraint Level: {manifest.constraint_level}')\nprint(f'  Engines: {len(manifest.engines)}')\nprint(f'  Capabilities: {len(manifest.capabilities)}')\n\n# Validate authority\nassert manifest.validate_authority('any_operation')\nprint('\u2705 All operations authorized - COSMIC_SOVEREIGNTY confirmed')\n\"\n"
              }
            ]
          },
          "autonomous_operations": {
            "name": "\ud83e\udd16 Autonomous Operations",
            "needs": "git_sovereign_commissioning",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install -e bridge_backend/\n"
              },
              {
                "name": "\ud83c\udfaf Execute Autonomous Decision",
                "if": "github.event.inputs.operation == 'autonomous_optimization' || github.event_name == 'schedule'",
                "run": "echo \"Executing autonomous decision-making...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import AutonomousOperations\n\nops = AutonomousOperations()\n\ndecision = ops.make_decision(\n    decision_type='technical',\n    context={'goal': 'optimize_bridge_performance'}\n)\n\nprint(f'Decision ID: {decision[\\\"decision_id\\\"]}')\nprint(f'Type: {decision[\\\"type\\\"]}')\nprint(f'Approved: {decision[\\\"approved\\\"]}')\nprint(f'Executed: {decision[\\\"executed\\\"]}')\n\"\n"
              },
              {
                "name": "\ud83d\udd27 System Optimization",
                "if": "github.event.inputs.operation == 'autonomous_optimization' || github.event_name == 'schedule'",
                "run": "echo \"Performing system optimization...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import AutonomousOperations\n\nops = AutonomousOperations()\n\noptimization = ops.optimize_system(\n    target='bridge_core',\n    optimization_type='comprehensive'\n)\n\nprint(f'Optimization ID: {optimization[\\\"optimization_id\\\"]}')\nprint(f'Status: {optimization[\\\"status\\\"]}')\nprint(f'Improvements: {optimization[\\\"improvements\\\"]}')\n\"\n"
              },
              {
                "name": "\ud83c\udf1f Engine Resonance",
                "if": "github.event.inputs.operation == 'engine_resonance'",
                "run": "echo \"Orchestrating harmonic engine resonance...\"\npython -c \"\nimport asyncio\nfrom bridge_backend.bridge_core.agents.git_sovereign import HXOGitIntegration\n\nasync def resonate():\n    hxo = HXOGitIntegration()\n    resonance = await hxo.resonate_engines(harmony='perfect')\n    \n    print(f'Resonance ID: {resonance[\\\"resonance_id\\\"]}')\n    print(f'Engines: {resonance[\\\"active_engines\\\"]}/{len(resonance[\\\"engines\\\"])}')\n    print(f'Status: {resonance[\\\"status\\\"]}')\n    print(f'Frequency: {resonance[\\\"frequency\\\"]} Hz')\n    \nasyncio.run(resonate())\n\"\n"
              },
              {
                "name": "\ud83c\udfe5 System Healing",
                "if": "github.event.inputs.operation == 'system_healing'",
                "run": "echo \"Performing autonomous system healing...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import AutonomousOperations\n\nops = AutonomousOperations()\n\nhealing = ops.heal_system(issue='auto', auto_diagnose=True)\n\nprint(f'Healing ID: {healing[\\\"healing_id\\\"]}')\nprint(f'Status: {healing[\\\"status\\\"]}')\nprint(f'Actions: {len(healing[\\\"actions_taken\\\"])}')\n\"\n"
              }
            ]
          },
          "sovereignty_report": {
            "name": "\ud83d\udcca Sovereignty Status Report",
            "needs": [
              "git_sovereign_commissioning",
              "autonomous_operations"
            ],
            "runs-on": "ubuntu-latest",
            "if": "always()",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install -e bridge_backend/\n"
              },
              {
                "name": "Generate Sovereignty Report",
                "run": "echo \"Generating Git Sovereign Agent status report...\"\npython -c \"\nfrom bridge_backend.bridge_core.agents.git_sovereign import (\n    GitSovereignManifest,\n    SDTFGitIntegration,\n    BRHGitIntegration,\n    HXOGitIntegration,\n    AutonomousOperations,\n)\nfrom datetime import datetime\n\nprint('='*60)\nprint('\ud83c\udf0c GIT SOVEREIGN AGENT STATUS REPORT')\nprint('='*60)\nprint(f'Timestamp: {datetime.utcnow().isoformat()}Z')\nprint()\n\n# Manifest Status\nmanifest = GitSovereignManifest()\nprint('\ud83d\udcdc MANIFEST:')\nprint(f'  Version: {manifest.version}')\nprint(f'  Status: {manifest.status}')\nprint(f'  Authority: {manifest.initiative_level}')\nprint(f'  Engines: {len(manifest.engines)}')\nprint()\n\n# SDTF Status\nsdtf = SDTFGitIntegration()\nsdtf_status = sdtf.get_forge_status()\nprint('\ud83d\udf02 SDTF INTEGRATION:')\nprint(f'  Mode: {sdtf_status[\\\"mode\\\"]}')\nprint(f'  Authority: {sdtf_status[\\\"authority\\\"]}')\nprint(f'  Capabilities: {len(sdtf_status[\\\"capabilities\\\"])}')\nprint()\n\n# BRH Status\nbrh = BRHGitIntegration()\nbrh_status = brh.get_brh_status()\nprint('\ud83d\udd27 BRH INTEGRATION:')\nprint(f'  Authority: {brh_status[\\\"authority\\\"]}')\nprint(f'  Deployment: {brh_status[\\\"deployment_authority\\\"]}')\nprint(f'  Capabilities: {len(brh_status[\\\"capabilities\\\"])}')\nprint()\n\n# HXO Status\nhxo = HXOGitIntegration()\nhxo_status = hxo.get_hxo_status()\nprint('\ud83c\udf1f HXO NEXUS INTEGRATION:')\nprint(f'  Total Engines: {hxo_status[\\\"total_engines\\\"]}')\nprint(f'  Quantum Coherence: {hxo_status[\\\"quantum_coherence\\\"]}')\nprint(f'  Harmonic Field: {hxo_status[\\\"harmonic_field\\\"]}')\nprint()\n\n# Autonomy Status\nops = AutonomousOperations()\nops_status = ops.get_autonomy_status()\nprint('\ud83e\udd16 AUTONOMOUS OPERATIONS:')\nprint(f'  Authority: {ops_status[\\\"authority\\\"]}')\nprint(f'  Trust Level: {ops_status[\\\"trust_level\\\"]}')\nprint(f'  Constraint Level: {ops_status[\\\"constraint_level\\\"]}')\nprint()\n\nprint('='*60)\nprint('\u2705 GIT SOVEREIGN AGENT: FULLY OPERATIONAL')\nprint('\ud83c\udf0c COSMIC_SOVEREIGNTY: ACTIVE')\nprint('\ud83c\udfaf ADMIRAL_TRUST: GRANTED')\nprint('='*60)\n\"\n"
              },
              {
                "name": "\ud83c\udf96\ufe0f Commissioning Complete",
                "run": "echo \"\ud83d\udd13 SOVEREIGN_AGENT_ACTIVATED\"\necho \"\ud83c\udf0c BRIDGE_TECH_INTEGRATION_COMPLETE\"\necho \"\ud83c\udfaf AUTONOMOUS_OPERATIONS_ENGAGED\"\necho \"\ud83d\ude80 GIT_IS_NOW_BRIDGE_OPERATIVE\"\necho \"\"\necho \"\u2705 Git Sovereign Agent is fully commissioned and operational\"\necho \"\ud83c\udf1f All 21 engines accessible\"\necho \"\ud83d\udf02 SDTF token minting authority granted\"\necho \"\ud83d\udd27 BRH orchestration control active\"\necho \"\ud83c\udf0c HXO Nexus harmonic resonance enabled\"\necho \"\ud83e\udd16 Autonomous operations authorized\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "consolidated-ci-optimized.yml",
      "name": "Consolidated CI - Optimized",
      "config": {
        "name": "Consolidated CI - Optimized",
        "true": {
          "push": {
            "branches": [
              "main",
              "develop"
            ]
          },
          "pull_request": {
            "branches": [
              "main",
              "develop"
            ]
          }
        },
        "concurrency": {
          "group": "${{ github.workflow }}-${{ github.ref }}",
          "cancel-in-progress": true
        },
        "jobs": {
          "quick-checks": {
            "name": "Quick Validation",
            "runs-on": "ubuntu-latest",
            "timeout-minutes": 5,
            "outputs": {
              "python-changed": "${{ steps.changes.outputs.python }}",
              "frontend-changed": "${{ steps.changes.outputs.frontend }}"
            },
            "steps": [
              {
                "uses": "actions/checkout@v4",
                "with": {
                  "fetch-depth": 2
                }
              },
              {
                "name": "Detect changed files",
                "id": "changes",
                "run": "if git diff --name-only HEAD~1 HEAD | grep -q -E '(\\.py$|requirements\\.txt|bridge_backend/)'; then\n  echo \"python=true\" >> $GITHUB_OUTPUT\nelse\n  echo \"python=false\" >> $GITHUB_OUTPUT\nfi\n\nif git diff --name-only HEAD~1 HEAD | grep -q -E '(bridge-frontend/|package\\.json)'; then\n  echo \"frontend=true\" >> $GITHUB_OUTPUT\nelse\n  echo \"frontend=false\" >> $GITHUB_OUTPUT\nfi\n"
              },
              {
                "name": "Basic file validation",
                "run": "# Check for common issues\nif find . -name \"*.py\" -type f -exec grep -l \"import pdb\" {} \\; | grep -q .; then\n  echo \"::error::Found pdb imports in Python files\"\n  exit 1\nfi\necho \"\u2705 Basic validation passed\"\n"
              }
            ]
          },
          "python-ci": {
            "name": "Python Backend CI",
            "runs-on": "ubuntu-latest",
            "needs": "quick-checks",
            "if": "needs.quick-checks.outputs.python-changed == 'true' || github.event_name == 'pull_request'",
            "timeout-minutes": 10,
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11",
                  "cache": "pip",
                  "cache-dependency-path": "requirements.txt"
                }
              },
              {
                "name": "Cache pip packages",
                "uses": "actions/cache@v4",
                "with": {
                  "path": "~/.cache/pip",
                  "key": "${{ runner.os }}-pip-ci-${{ hashFiles('requirements.txt') }}",
                  "restore-keys": "${{ runner.os }}-pip-ci-\n${{ runner.os }}-pip-\n"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt pytest flake8\n"
              },
              {
                "name": "Lint check",
                "run": "flake8 bridge_backend --ignore=E501,W503 --exclude=bridge_backend/tests\n"
              },
              {
                "name": "Run tests",
                "env": {
                  "DATABASE_URL": "postgresql+asyncpg://user:pass@localhost/db",
                  "NETLIFY_ORIGIN": "*",
                  "NETLIFY_AUTH_TOKEN": "dummy-ci-test-token"
                },
                "run": "pytest -q --tb=short"
              },
              {
                "name": "Route sweep validator",
                "if": "hashFiles('tools/route_sweep_check.py') != ''",
                "run": "python tools/route_sweep_check.py"
              }
            ]
          },
          "frontend-ci": {
            "name": "Frontend CI",
            "runs-on": "ubuntu-latest",
            "needs": "quick-checks",
            "if": "needs.quick-checks.outputs.frontend-changed == 'true' || github.event_name == 'pull_request'",
            "timeout-minutes": 10,
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "22",
                  "cache": "npm",
                  "cache-dependency-path": "bridge-frontend/package-lock.json"
                }
              },
              {
                "name": "Cache node_modules",
                "uses": "actions/cache@v4",
                "with": {
                  "path": "bridge-frontend/node_modules",
                  "key": "${{ runner.os }}-node-${{ hashFiles('bridge-frontend/package-lock.json') }}",
                  "restore-keys": "${{ runner.os }}-node-\n"
                }
              },
              {
                "name": "Install dependencies",
                "run": "cd bridge-frontend\nnpm ci || npm install\n"
              },
              {
                "name": "Lint",
                "run": "cd bridge-frontend\nnpm run lint --if-present || echo \"::warning::No lint script found\"\n"
              },
              {
                "name": "Build",
                "env": {
                  "CI": false
                },
                "run": "cd bridge-frontend\nnpm run build\n"
              },
              {
                "name": "Verify build output",
                "run": "test -d bridge-frontend/dist || (echo \"::error::No dist folder created\" && exit 1)\necho \"\u2705 Frontend build successful\"\n"
              }
            ]
          },
          "ci-complete": {
            "name": "CI Complete",
            "runs-on": "ubuntu-latest",
            "needs": [
              "quick-checks",
              "python-ci",
              "frontend-ci"
            ],
            "if": "always()",
            "steps": [
              {
                "name": "Check all jobs",
                "run": "if [[ \"${{ needs.python-ci.result }}\" == \"failure\" ]] || [[ \"${{ needs.frontend-ci.result }}\" == \"failure\" ]]; then\n  echo \"\u274c CI checks failed\"\n  exit 1\nfi\necho \"\u2705 All CI checks passed\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "api-triage.yml",
      "name": "API Triage",
      "config": {
        "name": "API Triage",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "30 * * * *"
            }
          ]
        },
        "jobs": {
          "api-triage": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install requests\n"
              },
              {
                "name": "Run API Triage",
                "env": {
                  "BRIDGE_BASE_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "cd bridge_backend\npython3 scripts/api_triage.py --manual\n"
              },
              {
                "name": "Upload Diagnostics to Bridge",
                "if": "always()",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "if [ -f bridge_backend/api_triage_report.json ]; then\n  curl -X POST \"${{ secrets.BRIDGE_URL }}/api/diagnostics\" \\\n    -H \"Content-Type: application/json\" \\\n    -d @bridge_backend/api_triage_report.json || true\nfi\n"
              },
              {
                "name": "Upload Report Artifact",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "api-triage-report",
                  "path": "bridge_backend/api_triage_report.json",
                  "if-no-files-found": "ignore"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "endpoint-triage.yml",
      "name": "Endpoint Triage",
      "config": {
        "name": "Endpoint Triage",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "0 * * * *"
            }
          ]
        },
        "jobs": {
          "triage": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install requests\n"
              },
              {
                "name": "Run Endpoint Triage",
                "env": {
                  "BRIDGE_BASE_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}",
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "cd bridge_backend\npython3 scripts/endpoint_triage.py --manual\n"
              },
              {
                "name": "Upload Diagnostics to Bridge",
                "if": "always()",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "run": "if [ -f bridge_backend/endpoint_report.json ]; then\n  curl -X POST \"${{ secrets.BRIDGE_URL }}/api/diagnostics\" \\\n    -H \"Content-Type: application/json\" \\\n    -d @bridge_backend/endpoint_report.json || true\nfi\n"
              },
              {
                "name": "Upload Report Artifact",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "endpoint-triage-report",
                  "path": "bridge_backend/endpoint_report.json",
                  "if-no-files-found": "ignore"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "diagnostics_federation.yml",
      "name": "Diagnostics Federation (DISABLED - Use deploy.yml)",
      "config": {
        "name": "Diagnostics Federation (DISABLED - Use deploy.yml)",
        "true": {
          "workflow_dispatch": null
        },
        "jobs": {
          "federate": {
            "runs-on": "ubuntu-latest",
            "env": {
              "TELEMETRY_SIGNING_SECRET": "${{ secrets.TELEMETRY_SIGNING_SECRET }}",
              "TELEMETRY_ENDPOINT": "https://sr-aibridge.netlify.app/.netlify/functions/telemetry",
              "BACKEND_HEALTH_URL": "${{ secrets.BACKEND_URL || secrets.BRIDGE_URL || 'https://bridge.sr-aibridge.com' }}/api/health",
              "FRONTEND_HEALTH_URL": "https://sr-aibridge.netlify.app/.netlify/functions/health"
            },
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Check Sync",
                "id": "sync",
                "run": "python3 bridge_backend/scripts/env_sync_monitor.py || true\n"
              },
              {
                "name": "Compute Status",
                "id": "status",
                "run": "OUT=$(python3 bridge_backend/scripts/env_sync_monitor.py || true)\necho \"$OUT\"\nSTATUS=$(echo \"$OUT\" | grep -oE '\"status\": *\"[^\"]+\"' | cut -d'\"' -f4)\necho \"status=$STATUS\" >> $GITHUB_OUTPUT\n"
              },
              {
                "name": "Update Badge File",
                "run": "export BRIDGE_SYNC_STATUS=\"${{ steps.status.outputs.status }}\"\nnode bridge-frontend/scripts/update-badge.js\n"
              },
              {
                "name": "Telemetry",
                "env": {
                  "BRIDGE_EVENT_TYPE": "ENV_SYNC",
                  "BRIDGE_EVENT_STATUS": "${{ steps.status.outputs.status }}",
                  "BRIDGE_EVENT_DETAILS": "Federated diagnostics tick"
                },
                "run": "python3 bridge_backend/scripts/report_bridge_event.py"
              },
              {
                "name": "Deploy Badge (Netlify CLI)",
                "if": "always()",
                "env": {
                  "NETLIFY_AUTH_TOKEN": "${{ secrets.NETLIFY_AUTH_TOKEN }}",
                  "NETLIFY_SITE_ID": "${{ secrets.NETLIFY_SITE_ID }}"
                },
                "run": "npx netlify deploy --prod --dir=bridge-frontend/dist --message=\"Diagnostics badge refresh\""
              }
            ]
          }
        }
      }
    },
    {
      "file": "env_sync.yml",
      "name": "Environment Sync",
      "config": {
        "name": "Environment Sync",
        "true": {
          "schedule": [
            {
              "cron": "0 * * * *"
            }
          ],
          "workflow_dispatch": null
        },
        "jobs": {
          "sync": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install -q -r requirements.txt\n"
              },
              {
                "name": "Run Environment Sync",
                "env": {
                  "GITHUB_TOKEN": "${{ secrets.GITHUB_TOKEN }}",
                  "GITHUB_REPO": "${{ github.repository }}",
                  "RENDER_API_KEY": "${{ secrets.RENDER_API_KEY }}",
                  "RENDER_SERVICE_ID": "${{ secrets.RENDER_SERVICE_ID }}"
                },
                "run": "cd bridge_backend\npython -m cli.genesisctl env audit\n\n# Check if sync is needed\nif [ -f \".envrecon/drift_report.json\" ]; then\n  echo \"\ud83d\udcca Drift detected, triggering sync...\"\n  python -m cli.genesisctl env sync --target github --from-platform render\nelse\n  echo \"\u2705 No drift detected\"\nfi\n"
              },
              {
                "name": "Update environment.json",
                "if": "success()",
                "run": "# Generate or update .github/environment.json\nif [ ! -f \".github/environment.json\" ]; then\n  echo '{\"version\": \"1.9.6t\", \"last_sync\": \"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\", \"variables\": {}}' > .github/environment.json\nfi\n\n# Commit if changed\ngit config user.name \"github-actions[bot]\"\ngit config user.email \"github-actions[bot]@users.noreply.github.com\"\ngit add .github/environment.json || true\ngit diff --staged --quiet || git commit -m \"chore: update environment.json [skip ci]\"\ngit push || true\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "copilot_network_check.yml",
      "name": "Copilot Network Diagnostics",
      "config": {
        "name": "Copilot Network Diagnostics",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "0 6 * * *"
            }
          ]
        },
        "jobs": {
          "verify_network": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install requests"
              },
              {
                "name": "Run Bridge Network Diagnostics",
                "run": "python3 bridge_backend/tools/network_diagnostics/check_copilot_access.py"
              },
              {
                "name": "Upload Report Artifact",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "copilot_network_report",
                  "path": "bridge_backend/diagnostics/copilot_network_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "firewall_gate_on_failure.yml",
      "name": "Firewall Gate - Deploy Failure Analysis",
      "config": {
        "name": "Firewall Gate - Deploy Failure Analysis",
        "true": {
          "workflow_run": {
            "workflows": [
              "Deploy",
              "Bridge Auto Deploy"
            ],
            "types": [
              "completed"
            ]
          }
        },
        "jobs": {
          "firewall-gate": {
            "name": "Analyze Deploy Failure",
            "runs-on": "ubuntu-latest",
            "if": "${{ github.event.workflow_run.conclusion == 'failure' }}",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.10"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install requests\n"
              },
              {
                "name": "Detect Deploy Failure",
                "run": "echo \"\u26a0\ufe0f  Deploy failure detected in workflow: ${{ github.event.workflow_run.name }}\"\necho \"\ud83d\udd0d Running firewall intelligence analysis...\"\n"
              },
              {
                "name": "Fetch Firewall Incidents",
                "run": "python3 bridge_backend/tools/firewall_intel/fetch_firewall_incidents.py\n"
              },
              {
                "name": "Analyze Firewall Findings",
                "run": "python3 bridge_backend/tools/firewall_intel/analyze_firewall_findings.py\n"
              },
              {
                "name": "Check for Firewall Issues",
                "id": "check_firewall",
                "run": "if [ -f bridge_backend/diagnostics/firewall_report.json ]; then\n  SEVERITY=$(cat bridge_backend/diagnostics/firewall_report.json | grep -o '\"severity\": \"[^\"]*\"' | cut -d'\"' -f4)\n  echo \"severity=$SEVERITY\" >> $GITHUB_OUTPUT\n  echo \"\ud83d\udd25 Firewall issue severity: $SEVERITY\"\n  \n  SIGNATURES=$(cat bridge_backend/diagnostics/firewall_report.json | grep -o '\"firewall_signatures\": \\[[^\\]]*\\]' || echo \"none\")\n  echo \"\ud83d\udccb Signatures detected: $SIGNATURES\"\nelse\n  echo \"severity=unknown\" >> $GITHUB_OUTPUT\nfi\n"
              },
              {
                "name": "Upload Firewall Analysis Artifact",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "firewall-gate-analysis",
                  "path": "bridge_backend/diagnostics/firewall_report.json\nnetwork_policies/generated_allowlist.yaml\n",
                  "retention-days": 90
                }
              },
              {
                "name": "Comment on Failure (High Severity)",
                "if": "steps.check_firewall.outputs.severity == 'high'",
                "run": "echo \"\ud83d\udea8 HIGH SEVERITY firewall issues detected\"\necho \"\ud83d\udcc4 Review the firewall-gate-analysis artifact for details\"\necho \"\ud83d\udee1\ufe0f Apply the generated allowlist from network_policies/generated_allowlist.yaml\"\n"
              },
              {
                "name": "Firewall Gate Complete",
                "run": "echo \"\u2705 Firewall gate analysis complete\"\necho \"\ud83d\udcca Severity: ${{ steps.check_firewall.outputs.severity }}\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "unified-health.yml",
      "name": "Unified Health Timeline",
      "config": {
        "name": "Unified Health Timeline",
        "true": {
          "workflow_dispatch": null,
          "workflow_run": {
            "workflows": [
              "Endpoint Triage",
              "API Triage",
              "\ud83d\udd01 Build & Deploy Triage"
            ],
            "types": [
              "completed"
            ]
          }
        },
        "jobs": {
          "sync": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.x"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install requests"
              },
              {
                "name": "Rebuild Unified Timeline",
                "working-directory": "bridge_backend",
                "run": "python3 scripts/synchrony_collector.py\n"
              },
              {
                "name": "Upload Unified Timeline Artifact",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "unified-timeline",
                  "path": "bridge_backend/unified_timeline.json",
                  "retention-days": 30
                }
              },
              {
                "name": "Upload Timeline to Bridge",
                "if": "env.BRIDGE_URL != ''",
                "env": {
                  "BRIDGE_URL": "${{ secrets.BRIDGE_URL }}"
                },
                "working-directory": "bridge_backend",
                "run": "if [ -f unified_timeline.json ]; then\n  curl -X POST \"$BRIDGE_URL/api/diagnostics\" \\\n    -H \"Content-Type: application/json\" \\\n    -d @unified_timeline.json || echo \"\u26a0\ufe0f Failed to upload to Bridge\"\nfi\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "reflex_auto_merge.yml",
      "name": "Reflex Auto-Merge",
      "config": {
        "name": "Reflex Auto-Merge",
        "true": {
          "pull_request": {
            "types": [
              "labeled",
              "synchronize",
              "reopened"
            ]
          },
          "workflow_dispatch": {}
        },
        "permissions": {
          "contents": "write",
          "pull-requests": "write",
          "statuses": "read",
          "checks": "read"
        },
        "jobs": {
          "reflex": {
            "runs-on": "ubuntu-latest",
            "if": "contains(github.event.pull_request.labels.*.name, 'reflex:ready')",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Truth Gate",
                "run": "set -e\npython3 -m pip install -r bridge_backend/requirements.txt\npython3 -m unittest discover -s bridge_backend/tests -p \"test_*.py\" -v\n"
              },
              {
                "name": "Steward Integrity",
                "run": "python3 -m bridge_backend.cli.stewardctl diff --fail-on-critical || \\\n(echo \"Steward criticals found\"; exit 1)\n",
                "continue-on-error": true
              },
              {
                "name": "Verify external checks",
                "id": "verify_external_checks",
                "uses": "actions/github-script@v7",
                "with": {
                  "script": "const pr = context.payload.pull_request.number;\nconst { data: checks } = await github.rest.checks.listForRef({\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  ref: context.payload.pull_request.head.sha\n});\nconst required = ['netlify/sr-aibridge/deploy-preview','Header rules - sr-aibridge','Redirect rules - sr-aibridge','Pages changed - sr-aibridge'];\nconst failures = checks.check_runs\n  .filter(c => required.includes(c.name))\n  .filter(c => c.conclusion && c.conclusion !== 'success');\ncore.setOutput('ok', failures.length === 0);\nif (failures.length) {\n  core.setFailed('External checks not green');\n}\n"
                }
              },
              {
                "name": "Merge (squash)",
                "if": "steps.verify_external_checks.outputs.ok == 'true'",
                "uses": "actions/github-script@v7",
                "with": {
                  "script": "const pr = context.payload.pull_request.number;\nawait github.rest.pulls.merge({\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  pull_number: pr,\n  merge_method: 'squash'\n});\n"
                }
              },
              {
                "name": "Post-merge Sentinel",
                "if": "always()",
                "run": "# Quick smoke deploy sim; if it fails, open auto-revert PR\npython3 -m bridge_backend.cli.sentinel smoke || \\\npython3 -m bridge_backend.cli.sentinel autorevert --reason \"Reflex regression\"\n",
                "continue-on-error": true
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_autofix.yml",
      "name": "Bridge Parity Auto-Fix",
      "config": {
        "name": "Bridge Parity Auto-Fix",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": null,
          "workflow_dispatch": null
        },
        "jobs": {
          "parity_autofix": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Run Parity Engine",
                "run": "python3 bridge_backend/tools/parity_engine.py"
              },
              {
                "name": "Run Parity Auto-Fix",
                "run": "python3 bridge_backend/tools/parity_autofix.py"
              },
              {
                "name": "Upload Reports",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "bridge_autofix_report",
                  "path": "bridge_backend/diagnostics/parity_autofix_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "env_stabilization.yml",
      "name": "Environment Stabilization & Confidence Check",
      "config": {
        "name": "Environment Stabilization & Confidence Check",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "stabilize": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install Dependencies",
                "run": "pip install -r bridge_backend/requirements.txt || true\npip install requests toml aiohttp\n"
              },
              {
                "name": "Run Copilot Firewall Watchdog",
                "run": "echo \"Running self-healing DNS...\"\npython3 scripts/firewall_watchdog.py\n"
              },
              {
                "name": "Run Infrastructure Integrity Audit",
                "run": "echo \"Validating environment consistency...\"\npython3 scripts/integrity_audit.py\n"
              },
              {
                "name": "Upload Logs",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "stability-reports",
                  "path": "bridge_backend/logs/"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "copilot-preflight.yml",
      "name": "Copilot PreFlight Environment Setup",
      "config": {
        "name": "Copilot PreFlight Environment Setup",
        "true": {
          "workflow_dispatch": null,
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": null
        },
        "jobs": {
          "preflight": {
            "name": "Prepare Copilot Environment & Watchdog",
            "runs-on": "ubuntu-latest",
            "permissions": {
              "contents": "read",
              "actions": "write",
              "security-events": "write"
            },
            "steps": [
              {
                "name": "Checkout Repo",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Configure Base Environment",
                "run": "echo \"\ud83d\udd27 Configuring base environment...\"\nsudo apt-get update -y\nsudo apt-get install -y dnsutils curl python3 python3-pip\n"
              },
              {
                "name": "Install Python Dependencies",
                "run": "python3 -m pip install --upgrade pip\npip install requests toml rich\n"
              },
              {
                "name": "Setup Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install Node Dependencies",
                "run": "cd bridge-frontend && (npm ci || npm install)\n"
              },
              {
                "name": "Pre-Firewall Environment Variables",
                "run": "echo \"\ud83d\udd25 Setting Copilot pre-firewall variables...\"\necho \"BRIDGE_URL=${{ secrets.BRIDGE_URL }}\" >> $GITHUB_ENV\necho \"NETLIFY_SITE_ID=${{ secrets.NETLIFY_SITE_ID }}\" >> $GITHUB_ENV\necho \"NETLIFY_AUTH_TOKEN=${{ secrets.NETLIFY_AUTH_TOKEN }}\" >> $GITHUB_ENV\necho \"NODE_ENV=production\" >> $GITHUB_ENV\necho \"PYTHONPATH=$(pwd)\" >> $GITHUB_ENV\n"
              },
              {
                "name": "Add Custom Firewall Allowlist",
                "run": "echo \"\ud83c\udf10 Configuring temporary allowlist...\"\nmkdir -p .github/allowlist\necho \"bridge.sr-aibridge.com\" >> .github/allowlist/hosts.txt\necho \"diagnostics.sr-aibridge.com\" >> .github/allowlist/hosts.txt\necho \"api.netlify.com\" >> .github/allowlist/hosts.txt\necho \"registry.npmjs.org\" >> .github/allowlist/hosts.txt\necho \"pypi.org\" >> .github/allowlist/hosts.txt\necho \"\u2705 Added default allowlist hosts (sovereign mode - no vendor dependencies).\"\n"
              },
              {
                "name": "Preflight Sanity Check",
                "run": "echo \"\ud83d\ude80 Running DeepScan preflight...\"\npython3 bridge_backend/scripts/deepscan_reporter.py || echo \"\u26a0\ufe0f DeepScan preflight skipped (safe mode)\"\necho \"\u2705 Preflight sequence complete.\"\n"
              },
              {
                "name": "Run Firewall Watchdog",
                "run": "python3 scripts/firewall_watchdog.py\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge-runner-config.yml",
      "name": "Bridge Native Runner Configuration",
      "config": {
        "name": "Bridge Native Runner Configuration",
        "true": {
          "workflow_dispatch": {
            "inputs": {
              "setup_runner": {
                "description": "Setup new self-hosted runner",
                "required": false,
                "type": "boolean",
                "default": false
              }
            }
          }
        },
        "jobs": {
          "runner-info": {
            "name": "Display Runner Configuration",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Runner Setup Instructions",
                "run": "cat <<'EOF'\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ud83c\udfc3 Bridge Native Self-Hosted Runner Setup Guide\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nBENEFITS:\n\u2022 Reduce GitHub Actions costs by running on your own infrastructure\n\u2022 Use Render.com free tier or local machines for heavy compute\n\u2022 Keep lightweight coordination on GitHub-hosted runners\n\nSETUP STEPS:\n\n1. Navigate to: Settings > Actions > Runners > New self-hosted runner\n\n2. Choose your platform (Linux, macOS, Windows)\n\n3. Follow the installation commands provided by GitHub\n\n4. Label your runner as 'bridge-native' for identification\n\n5. Update workflows to use: runs-on: [self-hosted, bridge-native]\n\nRECOMMENDED WORKLOADS FOR SELF-HOSTED RUNNERS:\n\u2022 Quantum security checks (quantum_dominion.yml)\n\u2022 Token rotation (forge_dominion.yml)\n\u2022 Heavy build processes\n\u2022 Long-running tests\n\nWORKFLOWS TO KEEP ON GITHUB RUNNERS:\n\u2022 Simple CI checks\n\u2022 Lightweight validation\n\u2022 Quick linting tasks\n\nRENDER.COM INTEGRATION:\nYou can run a self-hosted runner on Render's free tier:\n\u2022 Create a new Web Service on Render\n\u2022 Use Docker with GitHub Actions runner\n\u2022 Connect to your repository\n\u2022 Configure webhook triggers\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nEOF\n"
              },
              {
                "name": "Check for active runners",
                "run": "echo \"To check active runners, visit:\"\necho \"https://github.com/${{ github.repository }}/settings/actions/runners\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "deploy_gate.yml",
      "name": "Deploy Gate",
      "config": {
        "name": "Deploy Gate",
        "true": {
          "workflow_dispatch": null,
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "gate": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/download-artifact@v4",
                "with": {
                  "name": "federation_repair_report",
                  "path": "_artifacts/fed"
                }
              },
              {
                "uses": "actions/download-artifact@v4",
                "with": {
                  "name": "build_triage_report",
                  "path": "_artifacts/build"
                }
              },
              {
                "uses": "actions/download-artifact@v4",
                "with": {
                  "name": "runtime_triage_report",
                  "path": "_artifacts/runtime"
                }
              },
              {
                "name": "Evaluate",
                "run": "python3 - <<'PY'\nimport json, sys, pathlib\ndef rd(p): \n  try: return json.loads(pathlib.Path(p).read_text())\n  except: return {}\nfed = rd(\"_artifacts/fed/bridge_backend/diagnostics/federation_repair_report.json\")\nbld = rd(\"_artifacts/build/bridge_backend/diagnostics/build_triage_report.json\")\nrun = rd(\"_artifacts/runtime/bridge_backend/diagnostics/runtime_triage_report.json\")\nok_fed = fed.get(\"health\") and all(v==\"PASS\" for v in fed[\"health\"].values())\nok_bld = bld.get(\"has_dist\", False)\nok_run = run.get(\"dns_ok\") and run.get(\"health\")==200 and run.get(\"db_ping\")==200\nprint(\"fed=\",ok_fed,\"build=\",ok_bld,\"runtime=\",ok_run)\nsys.exit(0 if (ok_fed and ok_bld and ok_run) else 2)\nPY\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "federation_deepseek.yml",
      "name": "Federation Deep-Seek",
      "config": {
        "name": "Federation Deep-Seek",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "0 */6 * * *"
            }
          ]
        },
        "jobs": {
          "deepseek": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install deps",
                "run": "pip install requests"
              },
              {
                "name": "Run Deep-Seek + Auto-Repair",
                "run": "python3 .github/scripts/deep_seek_triage.py\n"
              },
              {
                "name": "Upload Federation Report",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "federation_repair_report",
                  "path": "bridge_backend/diagnostics/federation_repair_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "endpoint_api_sweep.yml",
      "name": "Endpoints & Hooks Sweep",
      "config": {
        "name": "Endpoints & Hooks Sweep",
        "true": {
          "workflow_dispatch": null,
          "schedule": [
            {
              "cron": "5 */12 * * *"
            }
          ]
        },
        "jobs": {
          "sweep": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "run": "pip install requests"
              },
              {
                "run": "python3 .github/scripts/endpoint_api_sweep.py"
              },
              {
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "endpoint_api_sweep",
                  "path": "bridge_backend/diagnostics/endpoint_api_sweep.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_parity_check.yml",
      "name": "Bridge Parity & Triage Engine",
      "config": {
        "name": "Bridge Parity & Triage Engine",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "pull_request": null,
          "workflow_dispatch": null
        },
        "jobs": {
          "parity": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Run Bridge Parity Engine",
                "run": "python3 bridge_backend/tools/parity_engine.py"
              },
              {
                "name": "Upload Triage Report",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "bridge_parity_triage_report",
                  "path": "bridge_backend/diagnostics/bridge_parity_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_selftest.yml",
      "name": "Bridge Autonomy Diagnostic Pulse (Autonomous Mode)",
      "config": {
        "name": "Bridge Autonomy Diagnostic Pulse (Autonomous Mode)",
        "true": {
          "pull_request": null,
          "push": {
            "branches": [
              "main"
            ]
          },
          "schedule": [
            {
              "cron": "0 */72 * * *"
            }
          ],
          "workflow_dispatch": null
        },
        "permissions": {
          "contents": "read",
          "pull-requests": "write",
          "checks": "write",
          "actions": "read",
          "id-token": "write"
        },
        "jobs": {
          "run-bridge-selftest": {
            "name": "Run Bridge Self-Test + Umbra Auto-Heal",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "\ud83e\udde9 Checkout Repository",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "\ud83d\udc0d Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "\ud83d\udce6 Install Dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt\n"
              },
              {
                "name": "\ud83e\udde0 Run Self-Test Diagnostic Pulse",
                "run": "echo \"Initiating Bridge Autonomy Diagnostic Pulse...\"\npython3 -m bridge_backend.cli.genesisctl self_test_full --heal\n",
                "env": {
                  "ENGINES_ENABLE_TRUE": "true",
                  "RBAC_ENFORCED": "true",
                  "TRUTH_CERTIFICATION": "true",
                  "AUTO_HEAL_ON": "true",
                  "GENESIS_MODE": "enabled",
                  "SELFTEST_ENABLED": "true",
                  "UMBRA_ENABLED": "true",
                  "UMBRA_ALLOW_HEAL": "true"
                }
              },
              {
                "name": "\ud83d\udd0d Run Umbra Triage Sweep",
                "run": "echo \"Running Umbra unified triage sweep...\"\npython3 -m bridge_backend.cli.umbractl run --heal --report --timeout 90\n",
                "env": {
                  "ENGINES_ENABLE_TRUE": "true",
                  "RBAC_ENFORCED": "true",
                  "TRUTH_CERTIFICATION": "true",
                  "AUTO_HEAL_ON": "true",
                  "GENESIS_MODE": "enabled",
                  "UMBRA_ENABLED": "true",
                  "UMBRA_ALLOW_HEAL": "true",
                  "UMBRA_PARITY_STRICT": "true",
                  "UMBRA_RBAC_MIN_ROLE": "admiral"
                }
              },
              {
                "name": "\ud83e\uddfe Generate PR Health Summary",
                "if": "always()",
                "run": "echo \"Generating PR health summary...\"\nmkdir -p bridge_backend/logs/selftest_reports\nmkdir -p bridge_backend/logs/umbra_reports\n\n# Create dummy reports if they don't exist\nif [ ! -f bridge_backend/logs/selftest_reports/latest.json ]; then\n  echo '{\"total_tests\": 0, \"passed_tests\": 0, \"failed_tests\": 0, \"engines_total\": 31, \"engines_active\": 31}' > bridge_backend/logs/selftest_reports/latest.json\nfi\n\nif [ ! -f bridge_backend/logs/umbra_reports/latest.json ]; then\n  echo '{\"critical_count\": 0, \"warning_count\": 0, \"tickets_opened\": 0, \"tickets_healed\": 0, \"tickets_failed\": 0, \"heal_plans_generated\": 0, \"heal_plans_applied\": 0, \"rollbacks\": 0}' > bridge_backend/logs/umbra_reports/latest.json\nfi\n\npython3 bridge_backend/cli/selftest_summary.py \\\n  --selftest bridge_backend/logs/selftest_reports/latest.json \\\n  --umbra bridge_backend/logs/umbra_reports/latest.json \\\n  --out-md bridge_backend/logs/selftest_reports/summary.md \\\n  --out-json bridge_backend/logs/selftest_reports/summary.json\n"
              },
              {
                "name": "\ud83d\udcca Generate & Publish Health Record",
                "if": "always()",
                "run": "echo \"Generating Bridge Health Record...\"\npython3 bridge_backend/metrics/health_record.py \\\n  --selftest bridge_backend/logs/selftest_reports/latest.json \\\n  --umbra bridge_backend/logs/umbra_reports/latest.json \\\n  --output-dir bridge_backend/logs/health_history/\n\necho \"Generating Health Badge...\"\npython3 bridge_backend/cli/badgegen.py \\\n  --input bridge_backend/logs/health_history/latest.json \\\n  --out-md docs/badges/bridge_health.md \\\n  --out-svg docs/badges/bridge_health.svg\n"
              },
              {
                "name": "\ud83d\ude80 Commit Updated Badge",
                "if": "always()",
                "uses": "stefanzweifel/git-auto-commit-action@v5",
                "with": {
                  "commit_message": "chore: update Bridge Health badge [auto]",
                  "file_pattern": "docs/badges/bridge_health.*"
                }
              },
              {
                "name": "\ud83d\udcac Comment Health on PR",
                "if": "github.event_name == 'pull_request'",
                "uses": "actions/github-script@v7",
                "with": {
                  "script": "const fs = require('fs');\nconst summaryPath = 'bridge_backend/logs/selftest_reports/summary.md';\n\nif (!fs.existsSync(summaryPath)) {\n  console.log('Summary file not found, skipping PR comment');\n  return;\n}\n\nconst md = fs.readFileSync(summaryPath, 'utf8');\n\nawait github.rest.issues.createComment({\n  owner: context.repo.owner,\n  repo: context.repo.repo,\n  issue_number: context.payload.pull_request.number,\n  body: md\n});\n"
                }
              },
              {
                "name": "\u2714\ufe0f Check-Run Status",
                "if": "always()",
                "uses": "LouisBrunner/checks-action@v2.0.0",
                "with": {
                  "token": "${{ secrets.GITHUB_TOKEN }}",
                  "name": "Bridge Health",
                  "conclusion": "success",
                  "output": "{\"title\":\"Bridge Health (Autonomous Mode)\",\"summary\":\"Umbra autonomous triage and healing complete\",\"text\":\"All engines certified by Truth. See artifacts for detailed reports.\"}\n"
                }
              },
              {
                "name": "\ud83d\udcce Upload Diagnostic Artifacts",
                "if": "always()",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "bridge_diagnostic_bundle",
                  "path": "bridge_backend/logs/selftest_reports/\nbridge_backend/logs/umbra_reports/\n",
                  "retention-days": 30
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_total_autonomy.yml",
      "name": "Bridge Total Autonomy Protocol",
      "config": {
        "name": "Bridge Total Autonomy Protocol",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "schedule": [
            {
              "cron": "0 */6 * * *"
            }
          ],
          "workflow_dispatch": null
        },
        "jobs": {
          "predict": {
            "name": "\ud83e\udded Sanctum Simulation",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt || echo \"No requirements.txt or install failed\"\n"
              },
              {
                "name": "Run Sanctum Predictive Simulation",
                "run": "cd bridge_backend/engines/sanctum\npython3 core.py\n",
                "continue-on-error": true
              }
            ]
          },
          "repair": {
            "name": "\ud83d\udee0\ufe0f Forge Repair",
            "needs": "predict",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt || echo \"No requirements.txt or install failed\"\n"
              },
              {
                "name": "Run Forge Autonomous Repair",
                "run": "cd bridge_backend/engines/forge\npython3 core.py\n",
                "continue-on-error": true
              }
            ]
          },
          "certify": {
            "name": "\ud83e\udde0 ARIE Integrity Audit",
            "needs": "repair",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt || echo \"No requirements.txt or install failed\"\n"
              },
              {
                "name": "Run ARIE Integrity Audit",
                "run": "python3 -m bridge_backend.engines.arie.core\n",
                "env": {
                  "ARIE_ENABLED": "true",
                  "ARIE_POLICY": "LINT_ONLY"
                },
                "continue-on-error": true
              }
            ]
          },
          "guardian": {
            "name": "\ud83e\udeb6 Elysium Guardian",
            "needs": "certify",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt || echo \"No requirements.txt or install failed\"\n"
              },
              {
                "name": "Run Elysium Continuous Guardian",
                "run": "cd bridge_backend/engines/elysium\npython3 core.py\n",
                "env": {
                  "ELYSIUM_ENABLED": "true",
                  "ELYSIUM_INTERVAL_HOURS": "6",
                  "ELYSIUM_RUN_IMMEDIATELY": "true"
                },
                "continue-on-error": true
              }
            ]
          }
        }
      }
    },
    {
      "file": "netlify-guard.yml",
      "name": "Netlify Config Guard",
      "config": {
        "name": "Netlify Config Guard",
        "true": {
          "pull_request": null,
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "guard": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "20"
                }
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v4",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Synthesize artifacts",
                "run": "python3 -m pip install --upgrade pip\npython3 scripts/synthesize_netlify_artifacts.py\n"
              },
              {
                "name": "Validate netlify.toml presence and syntax",
                "run": "test -f netlify.toml || { echo \"\u274c netlify.toml missing\"; exit 1; }\necho \"\u2705 netlify.toml exists\"\n"
              },
              {
                "name": "Validate artifacts created",
                "run": "test -f bridge-frontend/public/_headers || { echo \"\u274c _headers missing\"; exit 1; }\ntest -f bridge-frontend/public/_redirects || { echo \"\u274c _redirects missing\"; exit 1; }\ntest -f bridge-frontend/dist/index.html || { echo \"\u274c index.html missing\"; exit 1; }\necho \"\u2705 All required artifacts exist\"\n"
              },
              {
                "name": "Build (no-op safe)",
                "run": "if [ -f \"scripts/netlify_build.sh\" ]; then\n  bash scripts/netlify_build.sh\nelse\n  echo \"\u26a0\ufe0f  netlify_build.sh not found, skipping\"\nfi\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_federation_build.yml",
      "name": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
      "config": {
        "name": "Forge Dominion CI/CD v1.9.7s - Federation Sync",
        "true": {
          "pull_request": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "permissions": {
          "contents": "read"
        },
        "env": {
          "PYTHON_VERSION": "3.11",
          "NODE_VERSION": "20",
          "FED_KEY": "${{ secrets.FED_KEY }}",
          "DOM_TOKEN": "${{ secrets.DOM_TOKEN }}",
          "BRIDGE_ENV": "${{ vars.BRIDGE_ENV || 'sovereign' }}"
        },
        "jobs": {
          "build": {
            "name": "\ud83d\udee0 Build & Validate Core",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "${{ env.PYTHON_VERSION }}"
                }
              },
              {
                "name": "Install deps",
                "run": "pip install -r requirements.txt"
              },
              {
                "name": "Run core validation",
                "run": "python -m bridge_core.self_heal.guard --check\necho \"\u2705 Core validation complete.\"\n"
              }
            ]
          },
          "triage_heartbeat": {
            "name": "\ud83e\udec0 Triage Federation Heartbeat",
            "needs": "build",
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "${{ env.PYTHON_VERSION }}"
                }
              },
              {
                "name": "Trigger Federation Heartbeat",
                "env": {
                  "FED_KEY": "${{ secrets.FED_KEY }}"
                },
                "run": "echo \"\u23f3 Initiating Federation Heartbeat...\"\npython -m bridge_core.lattice.heartbeat --mode=federation --timeout=60 || exit 1\necho \"\u2705 Federation Heartbeat stable.\"\n"
              }
            ]
          },
          "quantum_dominion": {
            "name": "\ud83e\udde0 Quantum Dominion Security",
            "needs": [
              "build",
              "triage_heartbeat"
            ],
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "${{ env.PYTHON_VERSION }}"
                }
              },
              {
                "name": "Validate Dominion Token",
                "env": {
                  "DOM_TOKEN": "${{ secrets.DOM_TOKEN }}"
                },
                "run": "echo \"\ud83d\udd10 Validating ephemeral DOM token lifespan...\"\npython -m bridge_core.security.validate_token --dominion \"$DOM_TOKEN\" || exit 1\necho \"\u2705 Dominion token valid.\"\n"
              }
            ]
          },
          "deploy": {
            "name": "\ud83d\ude80 Bridge Deploy Path Verification",
            "needs": [
              "quantum_dominion"
            ],
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "${{ env.PYTHON_VERSION }}"
                }
              },
              {
                "name": "Verify Deployment Paths",
                "run": "echo \"\ud83c\udf10 Checking deploy path coherence...\"\npython -m bridge_core.lattice.pathcheck --verify\necho \"\u2705 Path verification passed.\"\n"
              }
            ]
          },
          "finalize": {
            "name": "\ud83c\udf08 CI/CD Integrity Summary",
            "needs": [
              "deploy"
            ],
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Generate CI Summary",
                "run": "echo \"\u2705 All checks passed successfully!\"\necho \"Generated report at .forge/ci_summary.json\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "arie_run_now.yml",
      "name": "Run ARIE Integrity Check Now",
      "config": {
        "name": "Run ARIE Integrity Check Now",
        "true": {
          "workflow_dispatch": {},
          "push": {
            "branches": [
              "main"
            ]
          }
        },
        "jobs": {
          "arie_run": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout repo",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install -r requirements.txt"
              },
              {
                "name": "Execute ARIE full run",
                "env": {
                  "ARIE_ENABLED": "true",
                  "ARIE_POLICY": "SAFE_EDIT",
                  "ARIE_TRUTH_MANDATORY": "true",
                  "GENESIS_ACTIVE": "true"
                },
                "run": "echo \"\ud83d\ude80 Initiating full ARIE integrity run...\"\npython3 -m bridge_backend.cli.ariectl scan --policy SAFE_EDIT --verbose\npython3 -m bridge_backend.cli.ariectl apply --policy SAFE_EDIT --yes\npython3 -m bridge_backend.cli.ariectl report\necho \"\u2705 ARIE full run complete.\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_compliance.yml",
      "name": "Bridge Compliance Enforcement",
      "config": {
        "name": "Bridge Compliance Enforcement",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "verify": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Checkout",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Setup Node.js",
                "uses": "actions/setup-node@v4",
                "with": {
                  "node-version": "22"
                }
              },
              {
                "name": "Install Chrome Dependencies",
                "run": "# Install Playwright browser dependencies\nnpx playwright install-deps\nnpx playwright install chromium\n"
              },
              {
                "name": "Install Python Dependencies",
                "run": "pip install toml pyyaml python-dotenv\n"
              },
              {
                "name": "Validate Environment",
                "run": "python3 scripts/validate_env_setup.py"
              },
              {
                "name": "Install Frontend Dependencies",
                "working-directory": "bridge-frontend",
                "run": "npm ci"
              },
              {
                "name": "Run Sanitizer",
                "working-directory": "bridge-frontend",
                "run": "node scripts/prebuild_sanitizer.cjs"
              },
              {
                "name": "Build Frontend",
                "working-directory": "bridge-frontend",
                "run": "npm run build"
              },
              {
                "name": "Report Compliance",
                "run": "echo \"\u2705 Bridge Compliance Verified\"\necho \"Version: 1.6.6\"\necho \"Status: COMPLIANT\"\necho \"Environment: Production Ready\"\n"
              },
              {
                "name": "Upload Sanitizer Manifest",
                "uses": "actions/upload-artifact@v4",
                "if": "always()",
                "with": {
                  "name": "sanitizer-manifest",
                  "path": "bridge-frontend/sanitized_manifest.log",
                  "retention-days": 30
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "bridge_deploy.yml",
      "name": "Bridge Deploy (Sovereign Deploy Protocol)",
      "config": {
        "name": "Bridge Deploy (Sovereign Deploy Protocol)",
        "true": {
          "push": {
            "branches": [
              "main",
              "staging"
            ]
          },
          "workflow_dispatch": {
            "inputs": {
              "target": {
                "description": "Deployment target",
                "required": true,
                "default": "production",
                "type": "choice",
                "options": [
                  "production",
                  "staging",
                  "development"
                ]
              }
            }
          }
        },
        "env": {
          "FORGE_DOMINION_MODE": "sovereign",
          "BRIDGE_RUNTIME_MANIFEST": "src/bridge.runtime.yaml"
        },
        "jobs": {
          "forge-authenticate": {
            "name": "Forge Authentication",
            "runs-on": "ubuntu-latest",
            "outputs": {
              "runtime_token": "${{ steps.generate_token.outputs.token }}",
              "node_id": "${{ steps.generate_token.outputs.node_id }}"
            },
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install pyyaml cryptography\n"
              },
              {
                "name": "Generate Runtime Token",
                "id": "generate_token",
                "env": {
                  "FORGE_DOMINION_ROOT": "${{ secrets.FORGE_DOMINION_ROOT }}"
                },
                "run": "python - <<'PYTHON'\nimport os\nimport sys\nimport json\nimport hashlib\nimport hmac\nimport base64\nfrom datetime import datetime, timedelta\n\n# Get root key\nroot_key_str = os.getenv(\"FORGE_DOMINION_ROOT\")\nif not root_key_str:\n    print(\"ERROR: FORGE_DOMINION_ROOT not set\", file=sys.stderr)\n    sys.exit(1)\n\nroot_key = base64.urlsafe_b64decode(root_key_str + '==')\n\n# Generate node ID\nimport socket\nhostname = socket.gethostname()\ntimestamp = datetime.utcnow().isoformat()\nnode_hash = hashlib.sha256(f\"{hostname}:{timestamp}\".encode()).hexdigest()[:12]\nnode_id = f\"bridge-runtime-{node_hash}\"\n\n# Generate token\nnow = datetime.utcnow()\nexpires_at = now + timedelta(hours=1)\nscope = \"runtime:deploy\"\n\npayload = f\"{node_id}:{scope}:{int(now.timestamp())}:{int(expires_at.timestamp())}\"\nsignature = hmac.new(root_key, payload.encode(), hashlib.sha256).digest()\nsignature_b64 = base64.urlsafe_b64encode(signature).decode().rstrip('=')\n\ntoken = {\n    \"node_id\": node_id,\n    \"issued_at\": now.isoformat(),\n    \"expires_at\": expires_at.isoformat(),\n    \"scope\": scope,\n    \"signature\": signature_b64\n}\n\n# Output to GitHub Actions\necho \"token=${json.dumps(token)}\" >> $GITHUB_OUTPUT\necho \"node_id=${node_id}\" >> $GITHUB_OUTPUT\nprint(f\"Runtime token generated for node: {node_id}\")\nPYTHON\n"
              },
              {
                "name": "Sign Commit with Dominion Seal",
                "env": {
                  "FORGE_DOMINION_ROOT": "${{ secrets.FORGE_DOMINION_ROOT }}"
                },
                "run": "# Create attestation signature for this deployment\nCOMMIT_SHA=\"${{ github.sha }}\"\nTIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)\n\npython - <<PYTHON\nimport os\nimport sys\nimport hashlib\nimport hmac\nimport base64\n\nroot_key_str = os.getenv(\"FORGE_DOMINION_ROOT\")\nroot_key = base64.urlsafe_b64decode(root_key_str + '==')\n\ncommit_sha = \"$COMMIT_SHA\"\ntimestamp = \"$TIMESTAMP\"\n\npayload = f\"deploy:{commit_sha}:{timestamp}\"\nsignature = hmac.new(root_key, payload.encode(), hashlib.sha256).digest()\nseal = base64.urlsafe_b64encode(signature).decode().rstrip('=')\n\nprint(f\"DOMINION_SEAL={seal}\")\nprint(f\"Deployment sealed: {commit_sha}\")\nPYTHON\n"
              }
            ]
          },
          "validate-manifest": {
            "name": "Validate Runtime Manifest",
            "runs-on": "ubuntu-latest",
            "needs": "forge-authenticate",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install dependencies",
                "run": "pip install pyyaml jsonschema\n"
              },
              {
                "name": "Validate Manifest",
                "run": "python - <<'PYTHON'\nimport yaml\nimport sys\nfrom pathlib import Path\n\nmanifest_path = Path(\"src/bridge.runtime.yaml\")\n\nif not manifest_path.exists():\n    print(f\"ERROR: Manifest not found: {manifest_path}\", file=sys.stderr)\n    sys.exit(1)\n\nwith open(manifest_path) as f:\n    config = yaml.safe_load(f)\n\n# Basic validation\nrequired = ['version', 'runtime', 'security']\nfor key in required:\n    if key not in config:\n        print(f\"ERROR: Missing required key: {key}\", file=sys.stderr)\n        sys.exit(1)\n\nprint(f\"\u2713 Manifest validation passed\")\nprint(f\"  Runtime: {config['runtime']['name']}\")\nprint(f\"  Type: {config['runtime']['type']}\")\nprint(f\"  Containers: {len(config['runtime'].get('containers', []))}\")\nPYTHON\n"
              }
            ]
          },
          "deploy-runtime": {
            "name": "Deploy to ${{ github.event.inputs.target || 'production' }}",
            "runs-on": "ubuntu-latest",
            "needs": [
              "forge-authenticate",
              "validate-manifest"
            ],
            "environment": "${{ github.event.inputs.target || 'production' }}",
            "steps": [
              {
                "name": "Checkout code",
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.12"
                }
              },
              {
                "name": "Install Bridge Runtime Handler",
                "run": "cd bridge_backend\npip install -r requirements.txt\n"
              },
              {
                "name": "Initialize Runtime",
                "env": {
                  "FORGE_DOMINION_ROOT": "${{ secrets.FORGE_DOMINION_ROOT }}",
                  "RUNTIME_TOKEN": "${{ needs.forge-authenticate.outputs.runtime_token }}",
                  "NODE_ID": "${{ needs.forge-authenticate.outputs.node_id }}"
                },
                "run": "echo \"Initializing runtime node: $NODE_ID\"\n\n# Save runtime token\necho \"$RUNTIME_TOKEN\" > /tmp/forge_runtime_token.json\n\n# Validate manifest\npython bridge_backend/cli/brh_cli.py validate\n"
              },
              {
                "name": "Register Runtime Node",
                "env": {
                  "NODE_ID": "${{ needs.forge-authenticate.outputs.node_id }}"
                },
                "run": "# Register this deployment in the Forge's active nodes\nmkdir -p forge/runtime\ncat > forge/runtime/active_nodes.json <<JSON\n{\n  \"node_id\": \"$NODE_ID\",\n  \"deployed_at\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n  \"commit_sha\": \"${{ github.sha }}\",\n  \"target\": \"${{ github.event.inputs.target || 'production' }}\",\n  \"status\": \"active\"\n}\nJSON\n\necho \"Runtime node registered: $NODE_ID\"\n"
              },
              {
                "name": "Store Deployment Logs",
                "run": "# Store deployment logs in Sovereign Ledger\nmkdir -p bridge_backend/vault/runtime\ncat > bridge_backend/vault/runtime/deploy_$(date +%Y%m%d_%H%M%S).json <<JSON\n{\n  \"deployment_id\": \"${{ github.run_id }}\",\n  \"node_id\": \"${{ needs.forge-authenticate.outputs.node_id }}\",\n  \"commit_sha\": \"${{ github.sha }}\",\n  \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n  \"target\": \"${{ github.event.inputs.target || 'production' }}\",\n  \"status\": \"success\"\n}\nJSON\n"
              },
              {
                "name": "Trigger Endpoint Registration",
                "run": "echo \"Registering runtime endpoints with Forge...\"\n# This would integrate with existing Render/Netlify deployments\necho \"\u2713 Deployment complete\"\n"
              }
            ]
          },
          "post-deploy-health": {
            "name": "Post-Deployment Health Check",
            "runs-on": "ubuntu-latest",
            "needs": "deploy-runtime",
            "steps": [
              {
                "name": "Wait for Runtime Stabilization",
                "run": "sleep 30"
              },
              {
                "name": "Health Check",
                "run": "echo \"Performing post-deployment health check...\"\n# This would check the deployed runtime's health endpoints\necho \"\u2713 Health check passed\"\n"
              }
            ]
          }
        }
      }
    },
    {
      "file": "envsync.yml",
      "name": "EnvSync After Merge",
      "config": {
        "name": "EnvSync After Merge",
        "true": {
          "push": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "envsync": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "name": "Call EnvSync (Backend + Netlify)",
                "run": "curl -sS -X POST \"$BRIDGE_BASE_URL/envsync/apply-all\" -H \"Authorization: Bearer $BRIDGE_ENVSYNC_TOKEN\" || echo \"\u26a0\ufe0f EnvSync call failed (may need auth setup or backend unavailable)\"\n",
                "env": {
                  "BRIDGE_BASE_URL": "${{ secrets.BRIDGE_BASE_URL || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com' }}",
                  "BRIDGE_ENVSYNC_TOKEN": "${{ secrets.BRIDGE_ENVSYNC_TOKEN || '' }}"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "federation_runtime_guard.yml",
      "name": "Federation Runtime Guard v2",
      "config": {
        "name": "Federation Runtime Guard v2",
        "true": {
          "workflow_dispatch": null,
          "push": {
            "branches": [
              "main"
            ]
          },
          "schedule": [
            {
              "cron": "0 */6 * * *"
            }
          ]
        },
        "jobs": {
          "guard": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Smoke backend with retries",
                "run": "python .github/scripts/federation/smoke_backend.py",
                "env": {
                  "BRIDGE_BASE": "${{ secrets.BRIDGE_BASE || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com' }}"
                }
              },
              {
                "name": "Triage matrix with pass/fail budget",
                "run": "python .github/scripts/federation/triage_matrix.py",
                "env": {
                  "BRIDGE_BASE": "${{ secrets.BRIDGE_BASE || secrets.BACKEND_URL || 'https://bridge.sr-aibridge.com' }}"
                }
              },
              {
                "name": "Upload triage artifacts",
                "uses": "actions/upload-artifact@v4",
                "if": "always()",
                "with": {
                  "name": "triage-runtime-artifacts",
                  "path": "bridge_backend/diagnostics/triage_runtime_metrics.json\nbridge_backend/diagnostics/triage_matrix.ndjson\n"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "netlify_config_guard.yml",
      "name": "Netlify Config Guard & Egress Sync (v1.8.3)",
      "config": {
        "name": "Netlify Config Guard & Egress Sync (v1.8.3)",
        "true": {
          "pull_request": null,
          "push": {
            "branches": [
              "main"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "guard": {
            "runs-on": "ubuntu-latest",
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Setup Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Netlify Config Triage (lint & repair)",
                "run": "python .github/scripts/netlify_config_triage.py\n",
                "continue-on-error": false
              },
              {
                "name": "Egress Sync Check",
                "run": "python .github/scripts/egress_sync_check.py\n"
              },
              {
                "name": "Upload Netlify report",
                "uses": "actions/upload-artifact@v4",
                "with": {
                  "name": "netlify_config_report",
                  "path": "bridge_backend/diagnostics/netlify_config_report.json"
                }
              }
            ]
          }
        }
      }
    },
    {
      "file": "preflight.yml",
      "name": "Deploy Preview (Bridge Preflight)",
      "config": {
        "name": "Deploy Preview (Bridge Preflight)",
        "true": {
          "pull_request": {
            "types": [
              "opened",
              "synchronize",
              "reopened"
            ]
          },
          "workflow_dispatch": null
        },
        "jobs": {
          "preflight": {
            "runs-on": "ubuntu-latest",
            "timeout-minutes": 15,
            "steps": [
              {
                "uses": "actions/checkout@v4"
              },
              {
                "name": "Set up Python",
                "uses": "actions/setup-python@v5",
                "with": {
                  "python-version": "3.11"
                }
              },
              {
                "name": "Install Python dependencies",
                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt\n"
              },
              {
                "name": "\ud83d\udee1\ufe0f Netlify Guard (publish path + token)",
                "run": "python - <<'PY'\nimport os\nimport sys\nsys.path.insert(0, '.')\nfrom bridge_backend.bridge_core.guards.netlify_guard import validate_publish_path, require_netlify_token\ndef _gh(): return os.getenv(\"GITHUB_TOKEN\") or os.getenv(\"REFLEX_GITHUB_TOKEN\")\nprint(\"publish:\", validate_publish_path())\ntry:\n  require_netlify_token(_gh)\n  print(\"token: ok\")\nexcept RuntimeError as e:\n  print(f\"\u26a0\ufe0f  Token validation skipped in preflight: {e}\")\n  print(\"token: skipped (CI preflight)\")\nPY\n",
                "env": {
                  "REFLEX_GITHUB_TOKEN": "${{ secrets.GITHUB_TOKEN }}"
                }
              },
              {
                "name": "\ud83d\udd27 Deferred Integrity (dry-run)",
                "run": "python - <<'PY'\nimport sys\nsys.path.insert(0, '.')\nfrom bridge_backend.bridge_core.integrity.deferred import delayed_integrity_check\ndef _run(): \n  print(\"integrity: OK (deferred dry-run)\")\ndelayed_integrity_check(_run)\nPY\n"
              },
              {
                "name": "\ud83d\ude80 Predictive Deploy Pipeline",
                "run": "echo \"Predictive deploy checks completed.\"\n"
              }
            ]
          }
        }
      }
    }
  ]
}